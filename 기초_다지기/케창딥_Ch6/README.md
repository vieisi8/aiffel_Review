# 학습 내용

---

- 작업정의
- 모델 개발
- 모델 배포

---

## 작업 정의

---

### 문제 정의

---

	머신 러닝 문제를 정의 -> 일반적으로 고객과 많은 세부 논의가 필요

	가장 우선순위가 높아야 할 질문

	- 입력 데이터는 무엇인가? 어떤 것을 예측하려 하나?
	- 문제의 종류가 무엇인가? (이진 분류? 다중 분류? 스칼라 회귀? 벡터 회귀? 다중 레이블 다중 분류? 이미지 분할? 랭킹? 클러스터링? 생성? 강화 학습?)
	- 기존 솔루션은 어떤 것이 있었나?
	- 고려해야 할 특별한 제약이 있나?

	가설 정의

		- 주어진 입력으로 타킷을 예측 가능 

		- 가용한 데이터에 입력과 출력 사이의 관계를 학습하는 데 충분한 정보가 있음

---

### 데이터 수집

---

	대부분의 머신 러닝 프로젝트에서 가장 힘들고 시간이 많이 걸리며 비용도 많이 드는 단계

	모델의 일반화 성능

		-> 훈련되는 데이터의 속성(데이터 포인트 개수, 레이블의 신뢰도, 특성 품질)에서 옴

---

데이터 애너테이션 인프라에 투자

데이터 애너테이션 과정

	타킷의 품질을 결정 -> 모델의 품질을 결정

방법 고려

	- 직접 데이터에 애너테이션을 수행?
	- 레이블을 모으기 위해 미케니컬 터크 같은 크라우드소싱 플랫폼 사용?
	- 전문적인 데이터 레이블링 회사의 서비스 이용?

		아웃소싱 -> 잠재적으로 시간과 비용을 절약 / 통제관이 넘어감

		미케니컬 터크 같은 서비스 -> 비용 절약, 쉬운 규모 확장 / 애너테이션에 잡음 발생 가능성 있음

최선의 옵션을 고르기 위한 현재 작업의 재약 조건 고려

	- 데이터에 레이블을 할당할 사람이 해당 분야의 전문가여야 하나? 아무나 레이블링을 할 수 있나?
	- 데이터 애너테이션에 전문적인 지식이 필요 하다면 이를 위해 사람을 훈련시킬 것 인가? 관련된 전문가를 구할 것 인가?
	- 전문가의 애너테이션 작업을 내가 이해 할 수 있나?

---

대표성 없는 데이터 주의

머신 러닝 모델 

	-> 이전에 본 샘플과 비슷한 입력만 이해 가능

		∴ 훈련에 사용하는 데이터가 제품 환경에 있는 데이터를 대표하는 것이 중요

	가능하다면 모델이 사용될 환경에서 직접 데이터 수집

		개념 이동 현상?

			제품 환경에서 데이터 속성이 시간에 따라 변할 때 일어남

		-> 모델의 정확도가 점진적으로 감소

---

### 데이터 이해

---

데이터셋을 블랙박스처럼 다루는 것

	-> 상당히 나쁜 방법!!!

	데이터를 탐색, 시각화하여 예측 능력을 가진 특성에 대한 통찰을 얻어야 함

		-> 특성 공학에 대한 정보를 얻고 가능성 있는 문제를 걸러 낼 수 있음

	- 데이터가 이미지나 자연어 텍스트를 포함한다면 몇개의 샘플, 레이블을 직접 확인 
	- 데이터가 수치 특성을 포함한다면 특성 값의 히스토그램을 그려 값의 범위나 빈도를 파악
	- 데이터가 위치 정보를 포함한다면 지도에 그려 뚜렷한 패턴이 있는지 확인
	- 결측 데이터가 존재한다면 데이터 전처리 
	- 분류 문제라면 데이터에 있는  각 클래스의 샘플 개수를 출력 -> 불균형이 존재 하는지 파악
	- 타갯 누출 확인(데이터에 타킷에 관한 정보를 제공하는 특성이 있는지 확인)

---

### 성공 지표 선택

---

어떤것을 제어하려면

	-> 관측이 가능해야 함

	성공이 무엇인가 먼저 정의 (정확도? 정밀도? 재현율? 고객 재방문율?)

		-> 고객의 비즈니스 성공처럼 고수준의 목표와 직접적으로 연결되어 있어야 함

	- 클래스 분포가 균일한 분류 문제 -> 정확도 & ROC AUC
	- 클래스 분포가 균일하지 않거나, 랭킹 문제, 다중 레이블 문제 -> 정밀도 & 재현율 / 정확도 & ROC AUC의 가중치 평균

---

## 모델 개발

---

대부분 튜토리얼, 연구 프로젝트는 이 단계만 수행

---

### 데이터 준비

---

일반적으로 원시 데이터 사용X

데이터 전처리의 목적

	주어진 원본 데이터를 신경망에 적용하기 쉽도록 만드는 것(벡터화, 정규화, 결측값 처리)

	많은 전처리 기법은 도메인에 특화(텍스트, 이미지 데이터에만 적용)

---

벡터화

	신경망에서 모든 입력과 타킷

		-> 일반적으로 부동 소수점 데이터로 이루어진 텐서(특정 경우 -> 정수 / 문자열로 이루어진 텐서)

	사운드, 이미지, 텍스트 등 -> 텐서로 변환

---

값 정규화

	ex)

	- (Mnist) float32 타입으로 변경후 255로 나눔
	- (주택 가격) 각 특성을 독립적으로 정규화 -> 평균=0, 표준편차=1

	네트워크를 쉽게 학습시키는 특징 2가지

	- 작은 값(0 ~ 1 사이 값)
	- 균일(모든 특성이 대체로 비슷한 범위)

---

누락된 값 처리하기

결측 특성을 완전히 삭제할 필요는 없음

	- 범주형 특성일때 '누락된 값'이라는 의미의 새로운 범주를 만드는 것이 안전 -> 타킷에 대해 이것이 의미하는 바를 자동으로 학습
	- 수치형 특성일때 특성의 평균이나 중간 값으로 대체

테스트 데이터에 범주형 특성이 누락

	네트워크가 누락된 값이 없는 대이터에서 훈련되었다면

		-> 이 네트워크는 누락된 값을 무시하는 법을 알지 못함!

---

### 평가 방법 선택

--- 

모든 모델링 결정

	-> 일반화 성능을 측정하는 검증 지표에 의해 내려짐

검증 과정의 목표

	-> 실전 제품 환경에서 어떤 성공 지표(ex) 정확도)를 사용할지 전확하게 추징하는 것

세가지 방법

	- 홀드아웃 검증(데이터가 풍부할 때 사용)
	- k-겹 교차 검증(홀드아웃을 사용하기에 샘플 개수가 적을 때 사용)
	- 반복 k-겹 교차 검증(데이터가 적고 매우 정확한 모델 평가가 필요할 때 사용)

---

### 기준 모델 뛰어넘기

---

모델의 초기 목표

	-> 총계적 검정력(아주 간단한 기준점)을 달성 

증점으로 둘 세가지

	- 특성 공학 -> 유용하지 않은 특성을 제외, 문제에 대한 지식을 사용해 유용할 것 같은 새 특성 개발
	- 구조에 대한 올바른 가정 -> 어떤 종류의 모델 구조를 사용?
	- 좋은 훈련 옵션 -> 어떤 손실 함수 사용?

		올바른 손실 함수 선택

			- 이진 분류 → sigmoid / binary_crossentropy

			- 단일 레이블 다중 분류 → softmax / catrgorical_crossentropy

			- 다중 레이블 다중 분류 → sigmoid / binary_crossentropy

간단한 기준점을 넘어서지 못한다면
	
	문제 정의에서 정의한 가설이 잘못된 것일 수 있음 -> 처음으로 돌아가야 함

---

### 모델 용량 키우기: 과대적합 모델 만들기

---

머신 러닝은 최적화로 일반화 사이의 줄다리기

	-> 괴소용량과 과대용량의 경계에 있는 모델이 이상적

과대적합 만드는 법

	- 층(layer)을 추가
	- 층의 크기를 크움
	- 더 많은 에포크 동안 훈련

모니터링 지표

	-> 훈련 손실, 검증 손실

---

### 모델 규제와 하이퍼파라미터 튜닝

---

	일반화 성능을 최대화하는 것이 목표

	- 다른 구조로 시도(층을 제거, 추가)
	- 드롭아웃 추가
	- 모델이 작을 경우 L1 / L2 규제 추가
	- 하이퍼파라미터 튜닝(층의 유닛 개수 / 옵티마이저의 학습률)
	- 선택적으로 데이터 큐레이션 / 특성 공학 시도

		-> 더 많은 데이터 수집, 애너테이션 만듦, 더 나은 특성 개발, 유용하지 않을 것 같은 특성 제거

주의사항

	검증 과정에서 얻은 피드백을 사용해 모델을 튜닝

		-> 검증 데이터를 모델에 누설(정보의 누설)
			
			-> 검증 과정의 신뢰도 감소

---

## 모델 배포

---

### 고객에게 작업 설명, 기대치 설정

---

성공과 고객의 신뢰

	사람들의 기대를 지속적으로 맞추거나 초과하여 얻음
		
		-> 실제 시스템은 이 그림의 절반, 나머지 절반은 출시 전에 적절한 기대치를 설정하는 일

기대치 설정 방법

	모델이 실패하는 경우를 모델의 성능 지표와 비즈니스 목표를 명확하게 연관지어 설명

출시할 때 적용할 핵심적인 파라미터 논의

	ex) 부정 거래로 표시할 확률 임계 값

		-> 절충점 필요하며 비즈니스에 깊은 이해가 있어야 함

---

### 추론 모델 배치하기

---

	1. 다른 방식으로 모델을 저장
		- 제품이 파이썬을 지원하지 않을 수 있음 → 모바일 앱, 임베디드 시스템
		- 애플리케이션이 파이썬으로 작성되지 않음 → 상당한 오버헤드 발생
	2. 제품 모델은 예측을 만들기 위해서만 사용 
		- 최적화 수행할 여지가 있음

---

Rest Api로 모델 배포하기

	- 가장 보편적인 방법
	- 서버나 클라우드 인스턴스에 텐서플로를 설치, Rest Api로 모델의 예측을 요청
	- 응답 속도에 대한 요구 사항이 염격하지 않거나 전달 되는 입력 데이터가 크게 민감하지 않아야됨
	- 직접 서비스를 구성할지, 관리형 서드파드 클라우드 서비스를 이용할지 결정

----

장치로 배포하기

	- 모델을 애플리케이션이 실행되는 동일한 장치에서 구동할 필요가 있음
	- 응답 속도에 대한 제약이 엄격하거나 인터넷 연걸이 불안정한 환경에서 실행될 때 사용
	- 메모리와 전력 조건을 고려해 상대적으로 낮은 성능의 모델 배포
	- 입력 데이터에 매우 민감한 정보가 포함될 때 사용
	- 텐서플로 라이트
        	
		-> 케라스 모델을 스마트폰이나 임베디드 장치에 배포하기 위한 솔루션

---
        
브라우저에 모델 배포하기

	- 사용자 컴퓨터 브라우저에서 바로 실행
	- 서버 비용을 크게 줄일 수 있음
	- 사용자의 하드웨어가 있어야함
	- 응답 속도 제약이 엄격할때 사용
	- 인터넷이 연결되지 않은 상태에서 작동하는 앱이 필요

		-> 모델이 충분히 작아 사용자읜 노트북이나 스마트폰의 하드웨어를 독차지 않을때 사용

주의사항

	전체 모델을 사옹자가 장치에 내려받음 ∴ 모델에 관해 비밀로 유지 해야할 것이 없어야 함

		-> 훈련된 딥러닝 모델에서 훈련 데이터에 대한 일부 정보를 복원할 수 있음

자바스크립트로 모델 배포

	딥러닝 라이브러리인 TensorFlow.js가 존재함

		-> 저장된 케라스 모델을 임포트해 앱의 일부로 사용 가능

---

추론  모델 최적화

널리 사용되는 두 가지 최적화 기법

	- 가중치 가지치기
		- 가장 큰 값만 남기면 모델 층에 있는 파라미터 개수를 크게 낮출 수 있음
        
			→ 성능에 약간의 손해를 보는 대신 모델이 사용하는 메모리와 계산 자원을 줄임
        
	- 가중치 양자화
		- 부동 소숫점 → 정수로 압축
        
			→ 크기는 1/4이지만 원본 모델의 정확도에 거의 가까운 추론용 모델을 얻을 수 있음

---

### 작동 중 모델 모니터링

---

새로운 데이터에서 성능과 다른 애플리케이션과 상호작용, 비즈니스 지표에 대한 최종 영향을 감시

	- 랜덤한 A/B 테스트를 사용해 모델의 영향과 다른 변결 사항을 격리
	- 가능하면 제품 횐경에서 모델의 예측을 정기적으로 수동 조사
	- 수동 조사가 불가능할 때 사용자 설문 같은 다른 평가 수단 고려

---

### 모델 유지 관리

---

시간이 지남에 따라 제품 환경의 데이터 속성이 변하고 점진적으로 모델의 성능과 타당성이 감소

	출시된 모델을 대체할 다음 세대 모델의 훈련 준비

		- 제품의 데이터에 대한 변화 감시
		- 계속 데이터를 수집, 애너테이션 수행
