{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a40ae9",
   "metadata": {},
   "source": [
    "# Step 0. 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "282ca6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import copy\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sentencepiece as spm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random_seed = 1234\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "\n",
    "# tf version 및 gpu 확인\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0347fa",
   "metadata": {},
   "source": [
    "# Step 1. Tokenizer 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c685b58",
   "metadata": {},
   "source": [
    "클라우드에 저장된 sentencepiece 모델을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e84ec325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07'\n",
    "model_dir = os.getenv('HOME')+'/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07'\n",
    "\n",
    "# vocab loading\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(f\"{model_dir}/ko_8000.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4d6e92",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리 (1) MASK 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5775990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_mask(tokens, mask_cnt, vocab_list):\n",
    "    \"\"\"\n",
    "    마스크 생성\n",
    "    :param tokens: tokens\n",
    "    :param mask_cnt: mask 개수 (전체 tokens의 15%)\n",
    "    :param vocab_list: vocab list (random token 용)\n",
    "    :return tokens: mask된 tokens\n",
    "    :return mask_idx: mask된 token의 index\n",
    "    :return mask_label: mask된 token의 원래 값\n",
    "    \"\"\"\n",
    "    # 단어 단위로 mask 하기 위해서 index 분할 (띄어쓰기)\n",
    "    cand_idx = []  # word 단위의 index array\n",
    "    for (i, token) in enumerate(tokens):\n",
    "        if token == \"[CLS]\" or token == \"[SEP]\":\n",
    "            continue\n",
    "        if 0 < len(cand_idx) and not token.startswith(u\"\\u2581\"):  # u\"\\u2581\"는 단어의 시작을 의미하는 값\n",
    "            cand_idx[-1].append(i)\n",
    "        else:\n",
    "            cand_idx.append([i])\n",
    "\n",
    "    # random mask를 위해서 순서를 섞음 (shuffle)\n",
    "    random.shuffle(cand_idx)\n",
    "\n",
    "    # masking\n",
    "    mask_lms = []  # mask 된 값\n",
    "    for index_set in cand_idx:\n",
    "        if len(mask_lms) >= mask_cnt:  # 핸재 mask된 개수가 15%를 넘으면 중지\n",
    "            break\n",
    "        if len(mask_lms) + len(index_set) > mask_cnt:  # 이번에 mask할 개수를 포함해 15%를 넘으면 skip\n",
    "            continue\n",
    "        dice = random.random()  # 0과 1 사이의 확률 값\n",
    "\n",
    "        for index in index_set:\n",
    "            # len(tokens) 이내에서만 접근하도록 제한\n",
    "            if index >= len(tokens):\n",
    "                continue\n",
    "            masked_token = None\n",
    "            if dice < 0.8:  # 80% replace with [MASK]\n",
    "                masked_token = \"[MASK]\"\n",
    "            elif dice < 0.9: # 10% keep original\n",
    "                masked_token = tokens[index]\n",
    "            else:  # 10% random word\n",
    "                masked_token = random.choice(vocab_list)\n",
    "            mask_lms.append({\"index\": index, \"label\": tokens[index]})\n",
    "            tokens[index] = masked_token\n",
    "\n",
    "    # mask_lms 정렬 후 mask_idx, mask_label 추출 (sorted 사용)\n",
    "    mask_lms = sorted(mask_lms, key=lambda x: x[\"index\"])\n",
    "    mask_idx = [p[\"index\"] for p in mask_lms]\n",
    "    mask_label = [p[\"label\"] for p in mask_lms]\n",
    "\n",
    "    return tokens, mask_idx, mask_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ac686",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 전처리 (2) NSP pair 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "403cb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_tokens(tokens_a, tokens_b, max_seq):\n",
    "    \"\"\"\n",
    "    tokens_a, tokens_b의 길이를 줄임 최대 길이: max_seq\n",
    "    :param tokens_a: tokens A\n",
    "    :param tokens_b: tokens B\n",
    "    :param max_seq: 두 tokens 길이의 최대 값\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        total_length = len(tokens_a) + len(tokens_b)\n",
    "        if total_length <= max_seq:\n",
    "            break\n",
    "\n",
    "        if len(tokens_a) > len(tokens_b):\n",
    "            del tokens_a[0]\n",
    "        else:\n",
    "            tokens_b.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7143853d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list):\n",
    "    \"\"\"\n",
    "    doc별 pretrain 데이터 생성\n",
    "    \"\"\"\n",
    "    # for CLS], [SEP], [SEP]\n",
    "    max_seq = n_seq - 3\n",
    "\n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i])  # line 단위로 추가\n",
    "        current_length += len(doc[i])  # current_chunk의 token 수\n",
    "        if 1 < len(current_chunk) and (i == len(doc) - 1 or current_length >= max_seq):  # 마지막 줄 이거나 길이가 max_seq 이상 인 경우\n",
    "\n",
    "            # token a\n",
    "            a_end = 1\n",
    "            if 1 < len(current_chunk):\n",
    "                a_end = random.randrange(1, len(current_chunk))\n",
    "            tokens_a = []\n",
    "            for j in range(a_end):\n",
    "                tokens_a.extend(current_chunk[j])\n",
    "            # token b\n",
    "            tokens_b = []\n",
    "            for j in range(a_end, len(current_chunk)):\n",
    "                tokens_b.extend(current_chunk[j])\n",
    "\n",
    "            if random.random() < 0.5:  # 50% 확률로 swap\n",
    "                is_next = 0    # False\n",
    "                tokens_t = tokens_a\n",
    "                tokens_a = tokens_b\n",
    "                tokens_b = tokens_t\n",
    "            else:\n",
    "                is_next = 1   # True\n",
    "            # max_seq 보다 큰 경우 길이 조절\n",
    "            trim_tokens(tokens_a, tokens_b, max_seq)\n",
    "            assert 0 < len(tokens_a)\n",
    "            assert 0 < len(tokens_b)\n",
    "\n",
    "            # tokens & segment 생성\n",
    "            tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "            segment = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "            \n",
    "            # mask\n",
    "            tokens, mask_idx, mask_label = create_pretrain_mask(tokens, int((len(tokens) - 3) * 0.15), vocab_list)\n",
    "\n",
    "            instance = {\n",
    "                \"tokens\": tokens,\n",
    "                \"segment\": segment,\n",
    "                \"is_next\": is_next,\n",
    "                \"mask_idx\": mask_idx,\n",
    "                \"mask_label\": mask_label\n",
    "            }\n",
    "            instances.append(instance)\n",
    "\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d72351a",
   "metadata": {},
   "source": [
    "# Step 4. 데이터 전처리 (3) 데이터셋 완성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "873e974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pretrain_data(vocab, in_file, out_file, n_seq, mask_prob=0.15):\n",
    "    \"\"\" pretrain 데이터 생성 \"\"\"\n",
    "    def save_pretrain_instances(out_f, doc):\n",
    "        instances = create_pretrain_instances(vocab, doc, n_seq, mask_prob, vocab_list)\n",
    "\n",
    "        for instance in instances:\n",
    "            out_f.write(json.dumps(instance, ensure_ascii=False))\n",
    "            out_f.write(\"\\n\")\n",
    "\n",
    "    # 특수문자 7개를 제외한 vocab_list 생성\n",
    "    vocab_list = []\n",
    "    for id in range(7, len(vocab)):\n",
    "        if not vocab.is_unknown(id):        # 생성되는 단어 목록이 unknown인 경우는 제거합니다. \n",
    "            vocab_list.append(vocab.id_to_piece(id))\n",
    "\n",
    "    # line count 확인\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        with open(out_file, \"w\") as out_f:\n",
    "            doc = []\n",
    "            for line in tqdm(in_f, total=line_cnt):\n",
    "                line = line.strip()\n",
    "                if line == \"\":  # line이 빈줄 일 경우 (새로운 단락)\n",
    "                    if 0 < len(doc):\n",
    "                        save_pretrain_instances(out_f, doc)\n",
    "                        \n",
    "                        doc = []\n",
    "                        if 0 < line_cnt:  # 테스트를 위해서 부분 처리함\n",
    "                            line_cnt -= 1\n",
    "                        else:\n",
    "                            break\n",
    "                else:  # line이 빈줄이 아닐 경우 tokenize 해서 doc에 저장\n",
    "                    pieces = vocab.encode_as_pieces(line)  # line을 토큰화하여 pieces에 저장\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "            if 0 < len(doc):  # 마지막에 처리되지 않은 doc가 있는 경우\n",
    "                save_pretrain_instances(out_f, doc)\n",
    "                \n",
    "                doc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1338ba35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a5b599f96d74d0da3d10715a28863fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3957761 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus_file = os.getenv('HOME')+'/aiffel/bert_pretrain/data/kowiki.txt'\n",
    "pretrain_json_path = os.getenv('HOME')+'/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.json'\n",
    "\n",
    "make_pretrain_data(vocab, corpus_file, pretrain_json_path, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1099aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pre_train_data(vocab, filename, n_seq, count=None):\n",
    "    \"\"\"\n",
    "    학습에 필요한 데이터를 로드\n",
    "    :param vocab: vocab\n",
    "    :param filename: 전처리된 json 파일\n",
    "    :param n_seq: 시퀀스 길이 (number of sequence)\n",
    "    :param count: 데이터 수 제한 (None이면 전체)\n",
    "    :return enc_tokens: encoder inputs\n",
    "    :return segments: segment inputs\n",
    "    :return labels_nsp: nsp labels\n",
    "    :return labels_mlm: mlm labels\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            total += 1\n",
    "            # 데이터 수 제한\n",
    "            if count is not None and count <= total:\n",
    "                break\n",
    "    \n",
    "    # np.memmap을 사용하면 메모리를 적은 메모리에서도 대용량 데이터 처리가 가능 함\n",
    "    enc_tokens = np.memmap(filename='enc_tokens.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    segments = np.memmap(filename='segments.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "    labels_nsp = np.memmap(filename='labels_nsp.memmap', mode='w+', dtype=np.int32, shape=(total,))\n",
    "    labels_mlm = np.memmap(filename='labels_mlm.memmap', mode='w+', dtype=np.int32, shape=(total, n_seq))\n",
    "\n",
    "    with open(filename, \"r\") as f:\n",
    "        for i, line in enumerate(tqdm(f, total=total)):\n",
    "            if total <= i:\n",
    "                print(\"data load early stop\", total, i)\n",
    "                break\n",
    "            data = json.loads(line)\n",
    "            # encoder token\n",
    "            enc_token = [vocab.piece_to_id(p) for p in data[\"tokens\"]]\n",
    "            enc_token += [0] * (n_seq - len(enc_token))\n",
    "            # segment\n",
    "            segment = data[\"segment\"]\n",
    "            segment += [0] * (n_seq - len(segment))\n",
    "            # nsp label\n",
    "            label_nsp = data[\"is_next\"]\n",
    "            # mlm label\n",
    "            mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
    "            mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
    "            label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n",
    "            label_mlm[mask_idx] = mask_label\n",
    "\n",
    "            assert len(enc_token) == len(segment) == len(label_mlm) == n_seq\n",
    "\n",
    "            enc_tokens[i] = enc_token\n",
    "            segments[i] = segment\n",
    "            labels_nsp[i] = label_nsp\n",
    "            labels_mlm[i] = label_mlm\n",
    "\n",
    "    return (enc_tokens, segments), (labels_nsp, labels_mlm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b725965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3046517efab54933b38a288dbf600300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_136/2049745891.py:42: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_idx = np.array(data[\"mask_idx\"], dtype=np.int)\n",
      "/tmp/ipykernel_136/2049745891.py:43: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_label = np.array([vocab.piece_to_id(p) for p in data[\"mask_label\"]], dtype=np.int)\n",
      "/tmp/ipykernel_136/2049745891.py:44: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  label_mlm = np.full(n_seq, dtype=np.int, fill_value=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data load early stop 128000 128000\n"
     ]
    }
   ],
   "source": [
    "# 128000건만 메모리에 로딩\n",
    "pre_train_inputs, pre_train_labels = load_pre_train_data(vocab, pretrain_json_path, 128, count=128000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a45fca5",
   "metadata": {},
   "source": [
    "# Step 5. BERT 모델 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d75184a",
   "metadata": {},
   "source": [
    "마스킹 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9662b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pad_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    pad mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: pad mask (pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    mask = tf.cast(tf.math.equal(tokens, i_pad), tf.float32)\n",
    "    mask = tf.expand_dims(mask, axis=1)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_ahead_mask(tokens, i_pad=0):\n",
    "    \"\"\"\n",
    "    ahead mask 계산하는 함수\n",
    "    :param tokens: tokens (bs, n_seq)\n",
    "    :param i_pad: id of pad\n",
    "    :return mask: ahead and pad mask (ahead or pad: 1, other: 0)\n",
    "    \"\"\"\n",
    "    n_seq = tf.shape(tokens)[1]\n",
    "    ahead_mask = 1 - tf.linalg.band_part(tf.ones((n_seq, n_seq)), -1, 0)\n",
    "    ahead_mask = tf.expand_dims(ahead_mask, axis=0)\n",
    "    pad_mask = get_pad_mask(tokens, i_pad)\n",
    "    mask = tf.maximum(ahead_mask, pad_mask)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f2c7950",
   "metadata": {},
   "source": [
    "GELU 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dee8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function(experimental_relax_shapes=True)\n",
    "def gelu(x):\n",
    "    \"\"\"\n",
    "    gelu activation 함수\n",
    "    :param x: 입력 값\n",
    "    :return: gelu activation result\n",
    "    \"\"\"\n",
    "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0851e16d",
   "metadata": {},
   "source": [
    "유틸리티 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc4cd16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_initializer(stddev=0.02):\n",
    "    \"\"\"\n",
    "    parameter initializer 생성\n",
    "    :param stddev: 생성할 랜덤 변수의 표준편차\n",
    "    \"\"\"\n",
    "    return tf.keras.initializers.TruncatedNormal(stddev=stddev)\n",
    "\n",
    "\n",
    "def bias_initializer():\n",
    "    \"\"\"\n",
    "    bias initializer 생성\n",
    "    \"\"\"\n",
    "    return tf.zeros_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a9f84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    \"\"\"\n",
    "    json을 config 형태로 사용하기 위한 Class\n",
    "    :param dict: config dictionary\n",
    "    \"\"\"\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        \"\"\"\n",
    "        file에서 Config를 생성 함\n",
    "        :param file: filename\n",
    "        \"\"\"\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read())\n",
    "            return Config(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c2056",
   "metadata": {},
   "source": [
    "Token Embedding 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c529774",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SharedEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Weighed Shaed Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"weight_shared_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.n_vocab = config.n_vocab\n",
    "        self.d_model = config.d_model\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        \"\"\"\n",
    "        shared weight 생성\n",
    "        :param input_shape: Tensor Shape (not used)\n",
    "        \"\"\"\n",
    "        with tf.name_scope(\"shared_embedding_weight\"):\n",
    "            self.shared_weights = self.add_weight(\n",
    "                \"weights\",\n",
    "                shape=[self.n_vocab, self.d_model],\n",
    "                initializer=kernel_initializer()\n",
    "            )\n",
    "\n",
    "    def call(self, inputs, mode=\"embedding\"):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :param mode: 실행 모드\n",
    "        :return: embedding or linear 실행 결과\n",
    "        \"\"\"\n",
    "        # mode가 embedding일 경우 embedding lookup 실행\n",
    "        if mode == \"embedding\":\n",
    "            return self._embedding(inputs)\n",
    "        # mode가 linear일 경우 linear 실행\n",
    "        elif mode == \"linear\":\n",
    "            return self._linear(inputs)\n",
    "        # mode가 기타일 경우 오류 발생\n",
    "        else:\n",
    "            raise ValueError(f\"mode {mode} is not valid.\")\n",
    "    \n",
    "    def _embedding(self, inputs):\n",
    "        \"\"\"\n",
    "        embedding lookup\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        embed = tf.gather(self.shared_weights, tf.cast(inputs, tf.int32))\n",
    "        return embed\n",
    "\n",
    "    def _linear(self, inputs):  # (bs, n_seq, d_model)\n",
    "        \"\"\"\n",
    "        linear 실행\n",
    "        :param inputs: 입력\n",
    "        \"\"\"\n",
    "        n_batch = tf.shape(inputs)[0]\n",
    "        n_seq = tf.shape(inputs)[1]\n",
    "        inputs = tf.reshape(inputs, [-1, self.d_model])  # (bs * n_seq, d_model)\n",
    "        outputs = tf.matmul(inputs, self.shared_weights, transpose_b=True)\n",
    "        outputs = tf.reshape(outputs, [n_batch, n_seq, self.n_vocab])  # (bs, n_seq, n_vocab)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297cdd7",
   "metadata": {},
   "source": [
    "Position Embedding 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc4291fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Embedding Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"position_embedding\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(config.n_seq, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: 입력\n",
    "        :return embed: position embedding lookup 결과\n",
    "        \"\"\"\n",
    "        position = tf.cast(tf.math.cumsum(tf.ones_like(inputs), axis=1, exclusive=True), tf.int32)\n",
    "        embed = self.embedding(position)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dc38e6",
   "metadata": {},
   "source": [
    "ScaleDotProductAttention 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "530618a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaleDotProductAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Scale Dot Product Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, name=\"scale_dot_product_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        attn_score = tf.matmul(Q, K, transpose_b=True)\n",
    "        scale = tf.math.sqrt(tf.cast(tf.shape(K)[-1], tf.float32))\n",
    "        attn_scale = tf.math.divide(attn_score, scale)\n",
    "        attn_scale -= 1.e9 * attn_mask\n",
    "        attn_prob = tf.nn.softmax(attn_scale, axis=-1)\n",
    "        attn_out = tf.matmul(attn_prob, V)\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec72a15c",
   "metadata": {},
   "source": [
    "MultiHeadAttention 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03451621",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Multi Head Attention Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"multi_head_attention\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.d_model = config.d_model\n",
    "        self.n_head = config.n_head\n",
    "        self.d_head = config.d_head\n",
    "\n",
    "        # Q, K, V input dense layer\n",
    "        self.W_Q = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_K = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_V = tf.keras.layers.Dense(config.n_head * config.d_head, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        # Scale Dot Product Attention class\n",
    "        self.attention = ScaleDotProductAttention(name=\"self_attention\")\n",
    "        # output dense layer\n",
    "        self.W_O = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, attn_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param Q: Q value\n",
    "        :param K: K value\n",
    "        :param V: V value\n",
    "        :param attn_mask: 실행 모드\n",
    "        :return attn_out: attention 실행 결과\n",
    "        \"\"\"\n",
    "        # reshape Q, K, V, attn_mask\n",
    "        batch_size = tf.shape(Q)[0]\n",
    "        Q_m = tf.transpose(tf.reshape(self.W_Q(Q), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, Q_len, d_head)\n",
    "        K_m = tf.transpose(tf.reshape(self.W_K(K), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        V_m = tf.transpose(tf.reshape(self.W_V(V), [batch_size, -1, self.n_head, self.d_head]), [0, 2, 1, 3])  # (bs, n_head, K_len, d_head)\n",
    "        attn_mask_m = tf.expand_dims(attn_mask, axis=1)\n",
    "        # Scale Dot Product Attention with multi head Q, K, V, attn_mask\n",
    "        attn_out = tf.map_fn(lambda x: self.attention(x[0], x[1], x[2], x[3]), \n",
    "                     elems=(Q_m, K_m, V_m, attn_mask_m), \n",
    "                     dtype=tf.float32) # (bs, n_head, Q_len, d_head)\n",
    "        # transpose and liner\n",
    "        attn_out = tf.transpose(attn_out, [0, 2, 1, 3])  # (bs, Q_len, n_head, d_head)\n",
    "        attn_out = tf.reshape(attn_out, [batch_size, -1, self.d_model])  # (bs, Q_len, d_model)\n",
    "        attn_out = self.W_O(attn_out) # (bs, Q_len, d_model)\n",
    "\n",
    "        return attn_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153f15b7",
   "metadata": {},
   "source": [
    "PositionWiseFeedForward 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29995a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Position Wise Feed Forward Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"feed_forward\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.W_1 = tf.keras.layers.Dense(config.d_ff, activation=gelu, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.W_2 = tf.keras.layers.Dense(config.d_model, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: inputs\n",
    "        :return ff_val: feed forward 실행 결과\n",
    "        \"\"\"\n",
    "        ff_val = self.W_2(self.W_1(inputs))\n",
    "        return ff_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b5f9e7",
   "metadata": {},
   "source": [
    "EncoderLayer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd13998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Encoder Layer Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"encoder_layer\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.self_attention = MultiHeadAttention(config)\n",
    "        self.norm1 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.ffn = PositionWiseFeedForward(config)\n",
    "        self.norm2 = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    " \n",
    "    def call(self, enc_embed, self_mask):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param enc_embed: enc_embed 또는 이전 EncoderLayer의 출력\n",
    "        :param self_mask: enc_tokens의 pad mask\n",
    "        :return enc_out: EncoderLayer 실행 결과\n",
    "        \"\"\"\n",
    "        self_attn_val = self.self_attention(enc_embed, enc_embed, enc_embed, self_mask)\n",
    "        norm1_val = self.norm1(enc_embed + self.dropout(self_attn_val))\n",
    "\n",
    "        ffn_val = self.ffn(norm1_val)\n",
    "        enc_out = self.norm2(norm1_val + self.dropout(ffn_val))\n",
    "\n",
    "        return enc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81811282",
   "metadata": {},
   "source": [
    "BERT Layer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e1261a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    BERT Class\n",
    "    \"\"\"\n",
    "    def __init__(self, config, name=\"bert\"):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param config: Config 객체\n",
    "        :param name: layer name\n",
    "        \"\"\"\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.i_pad = config.i_pad\n",
    "        self.embedding = SharedEmbedding(config)\n",
    "        self.position = PositionEmbedding(config)\n",
    "        self.segment = tf.keras.layers.Embedding(2, config.d_model, embeddings_initializer=kernel_initializer())\n",
    "        self.norm = tf.keras.layers.LayerNormalization(epsilon=config.layernorm_epsilon)\n",
    "        \n",
    "        self.encoder_layers = [EncoderLayer(config, name=f\"encoder_layer_{i}\") for i in range(config.n_layer)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(config.dropout)\n",
    "\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        layer 실행\n",
    "        :param inputs: (enc_tokens, segments)\n",
    "        :return logits: dec_tokens에 대한 다음 토큰 예측 결과 logits\n",
    "        \"\"\"\n",
    "        enc_tokens, segments = inputs\n",
    "\n",
    "        enc_self_mask = tf.keras.layers.Lambda(get_pad_mask, output_shape=(1, None), name='enc_self_mask')(enc_tokens, self.i_pad)\n",
    "\n",
    "        enc_embed = self.get_embedding(enc_tokens, segments)\n",
    "\n",
    "        enc_out = self.dropout(enc_embed)\n",
    "        for encoder_layer in self.encoder_layers:\n",
    "            enc_out = encoder_layer(enc_out, enc_self_mask)\n",
    "\n",
    "        logits_cls = enc_out[:,0]\n",
    "        logits_lm = self.embedding(enc_out, mode=\"linear\")\n",
    "        return logits_cls, logits_lm\n",
    "    \n",
    "    def get_embedding(self, tokens, segments):\n",
    "        \"\"\"\n",
    "        token embedding, position embedding lookup\n",
    "        :param tokens: 입력 tokens\n",
    "        :param segments: 입력 segments\n",
    "        :return embed: embedding 결과\n",
    "        \"\"\"\n",
    "        embed = self.embedding(tokens) + self.position(tokens) + self.segment(segments)\n",
    "        embed = self.norm(embed)\n",
    "        return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b03726",
   "metadata": {},
   "source": [
    "Encoder Layer class 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6ff1eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PooledOutput(tf.keras.layers.Layer):\n",
    "    def __init__(self, config, n_output, name=\"pooled_output\"):\n",
    "        super().__init__(name=name)\n",
    "\n",
    "        self.dense1 = tf.keras.layers.Dense(config.d_model, activation=tf.nn.tanh, kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    "        self.dense2 = tf.keras.layers.Dense(n_output, use_bias=False, activation=tf.nn.softmax, name=\"nsp\", kernel_initializer=kernel_initializer(), bias_initializer=bias_initializer())\n",
    " \n",
    "    def call(self, inputs):\n",
    "        outputs = self.dense1(inputs)\n",
    "        outputs = self.dense2(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5497741",
   "metadata": {},
   "source": [
    "build model 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3fe3a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_pre_train(config):\n",
    "    enc_tokens = tf.keras.layers.Input((None,), name=\"enc_tokens\")\n",
    "    segments = tf.keras.layers.Input((None,), name=\"segments\")\n",
    "\n",
    "    bert = BERT(config)\n",
    "    logits_cls, logits_lm = bert((enc_tokens, segments))\n",
    "\n",
    "    logits_cls = PooledOutput(config, 2, name=\"pooled_nsp\")(logits_cls)\n",
    "    outputs_nsp = tf.keras.layers.Softmax(name=\"nsp\")(logits_cls)\n",
    "\n",
    "    outputs_mlm = tf.keras.layers.Softmax(name=\"mlm\")(logits_lm)\n",
    "\n",
    "    model = tf.keras.Model(inputs=(enc_tokens, segments), outputs=(outputs_nsp, outputs_mlm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab063052",
   "metadata": {},
   "source": [
    "# Step 6. pretrain 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eac02ce",
   "metadata": {},
   "source": [
    "config 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "832c0ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config({\"d_model\": 256, \"n_head\": 4, \"d_head\": 64, \"dropout\": 0.1, \"d_ff\": 1024, \"layernorm_epsilon\": 0.001, \"n_layer\": 3, \"n_seq\": 256, \"n_vocab\": 0, \"i_pad\": 0})\n",
    "config.n_vocab = len(vocab)\n",
    "config.i_pad = vocab.pad_id()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147acba0",
   "metadata": {},
   "source": [
    "loss 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4baa424e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    loss 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # loss 계산\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)(y_true, y_pred)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=loss.dtype)\n",
    "    loss *= mask\n",
    "    return loss * 20  # mlm을 더 잘 학습하도록 20배 증가 시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495f6791",
   "metadata": {},
   "source": [
    "accuracy 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1ca3d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lm_acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    acc 계산 함수\n",
    "    :param y_true: 정답 (bs, n_seq)\n",
    "    :param y_pred: 예측 값 (bs, n_seq, n_vocab)\n",
    "    \"\"\"\n",
    "    # 정답 여부 확인\n",
    "    y_pred_class = tf.cast(K.argmax(y_pred, axis=-1), tf.float32)\n",
    "    matches = tf.cast(K.equal(y_true, y_pred_class), tf.float32)\n",
    "    # pad(0) 인 부분 mask\n",
    "    mask = tf.cast(tf.math.not_equal(y_true, 0), dtype=matches.dtype)\n",
    "    matches *= mask\n",
    "    # 정확도 계산\n",
    "    accuracy = K.sum(matches) / K.maximum(K.sum(mask), 1)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed389c66",
   "metadata": {},
   "source": [
    "Learning Rate 스케쥴링 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ca849b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    \"\"\"\n",
    "    CosineSchedule Class\n",
    "    \"\"\"\n",
    "    def __init__(self, train_steps=4000, warmup_steps=2000, max_lr=2.5e-4):\n",
    "        \"\"\"\n",
    "        생성자\n",
    "        :param train_steps: 학습 step 총 합\n",
    "        :param warmup_steps: warmup steps\n",
    "        :param max_lr: 최대 learning rate\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        assert 0 < warmup_steps < train_steps\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.train_steps = train_steps\n",
    "        self.max_lr = max_lr\n",
    "\n",
    "    def __call__(self, step_num):\n",
    "        \"\"\"\n",
    "        learning rate 계산\n",
    "        :param step_num: 현재 step number\n",
    "        :retrun: 계산된 learning rate\n",
    "        \"\"\"\n",
    "        state = tf.cast(step_num <= self.warmup_steps, tf.float32)\n",
    "        lr1 = tf.cast(step_num, tf.float32) / self.warmup_steps\n",
    "        progress = tf.cast(step_num - self.warmup_steps, tf.float32) / max(1, self.train_steps - self.warmup_steps)\n",
    "        lr2 = 0.5 * (1.0 + tf.math.cos(math.pi * progress))\n",
    "        return (state * lr1 + (1 - state) * lr2) * self.max_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45feaac0",
   "metadata": {},
   "source": [
    "model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38fd0b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:617: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "enc_tokens (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segments (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert (BERT)                     ((None, 256), (None, 4485632     enc_tokens[0][0]                 \n",
      "                                                                 segments[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pooled_nsp (PooledOutput)       (None, 2)            66304       bert[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "nsp (Softmax)                   (None, 2)            0           pooled_nsp[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "mlm (Softmax)                   (None, None, 8007)   0           bert[0][1]                       \n",
      "==================================================================================================\n",
      "Total params: 4,551,936\n",
      "Trainable params: 4,551,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pre_train_model = build_model_pre_train(config)\n",
    "pre_train_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fa33fd",
   "metadata": {},
   "source": [
    "model compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d845cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_steps: 20000\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "\n",
    "# optimizer\n",
    "train_steps = math.ceil(len(pre_train_inputs[0]) / batch_size) * epochs\n",
    "print(\"train_steps:\", train_steps)\n",
    "learning_rate = CosineSchedule(train_steps=train_steps, warmup_steps=max(100, train_steps // 10))\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# compile\n",
    "pre_train_model.compile(loss=(tf.keras.losses.sparse_categorical_crossentropy, lm_loss), optimizer=optimizer, metrics={\"nsp\": \"acc\", \"mlm\": lm_acc})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca95483",
   "metadata": {},
   "source": [
    "model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80f4fdbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 562s 278ms/step - loss: 19.5987 - nsp_loss: 0.6503 - mlm_loss: 18.9484 - nsp_acc: 0.5899 - mlm_lm_acc: 0.1099\n",
      "\n",
      "Epoch 00001: mlm_lm_acc improved from -inf to 0.10990, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 555s 278ms/step - loss: 17.5316 - nsp_loss: 0.6226 - mlm_loss: 16.9090 - nsp_acc: 0.6175 - mlm_lm_acc: 0.1294\n",
      "\n",
      "Epoch 00002: mlm_lm_acc improved from 0.10990 to 0.12936, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 16.4468 - nsp_loss: 0.6156 - mlm_loss: 15.8312 - nsp_acc: 0.6240 - mlm_lm_acc: 0.1433\n",
      "\n",
      "Epoch 00003: mlm_lm_acc improved from 0.12936 to 0.14332, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 14.4273 - nsp_loss: 0.6140 - mlm_loss: 13.8133 - nsp_acc: 0.6275 - mlm_lm_acc: 0.1817\n",
      "\n",
      "Epoch 00004: mlm_lm_acc improved from 0.14332 to 0.18167, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 555s 277ms/step - loss: 13.5346 - nsp_loss: 0.6085 - mlm_loss: 12.9261 - nsp_acc: 0.6353 - mlm_lm_acc: 0.2061\n",
      "\n",
      "Epoch 00005: mlm_lm_acc improved from 0.18167 to 0.20612, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 13.0369 - nsp_loss: 0.6035 - mlm_loss: 12.4334 - nsp_acc: 0.6452 - mlm_lm_acc: 0.2215\n",
      "\n",
      "Epoch 00006: mlm_lm_acc improved from 0.20612 to 0.22146, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 554s 277ms/step - loss: 12.7121 - nsp_loss: 0.5984 - mlm_loss: 12.1137 - nsp_acc: 0.6577 - mlm_lm_acc: 0.2322\n",
      "\n",
      "Epoch 00007: mlm_lm_acc improved from 0.22146 to 0.23221, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 553s 277ms/step - loss: 12.4939 - nsp_loss: 0.5927 - mlm_loss: 11.9013 - nsp_acc: 0.6673 - mlm_lm_acc: 0.2396\n",
      "\n",
      "Epoch 00008: mlm_lm_acc improved from 0.23221 to 0.23958, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 553s 277ms/step - loss: 12.3656 - nsp_loss: 0.5880 - mlm_loss: 11.7775 - nsp_acc: 0.6756 - mlm_lm_acc: 0.2439\n",
      "\n",
      "Epoch 00009: mlm_lm_acc improved from 0.23958 to 0.24393, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 556s 278ms/step - loss: 12.3064 - nsp_loss: 0.5854 - mlm_loss: 11.7210 - nsp_acc: 0.6800 - mlm_lm_acc: 0.2460\n",
      "\n",
      "Epoch 00010: mlm_lm_acc improved from 0.24393 to 0.24599, saving model to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd07/bert_pre_train.hdf5\n"
     ]
    }
   ],
   "source": [
    "# save weights callback\n",
    "save_weights = tf.keras.callbacks.ModelCheckpoint(f\"{model_dir}/bert_pre_train.hdf5\", monitor=\"mlm_lm_acc\", verbose=1, save_best_only=True, mode=\"max\", save_freq=\"epoch\", save_weights_only=True)\n",
    "# train\n",
    "history = pre_train_model.fit(\n",
    "    pre_train_inputs,          # 학습 데이터 입력\n",
    "    pre_train_labels,          # 학습 데이터 라벨\n",
    "    epochs=epochs,             # 학습할 에포크 수\n",
    "    batch_size=batch_size,     # 배치 크기\n",
    "    callbacks=[save_weights]   # 콜백 리스트, 가중치 저장 콜백 포함\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9f125",
   "metadata": {},
   "source": [
    "시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51846a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['nsp_loss'], 'b-', label='nsp_loss')\n",
    "plt.plot(history.history['mlm_loss'], 'r--', label='mlm_loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['nsp_acc'], 'g-', label='nsp_acc')\n",
    "plt.plot(history.history['mlm_lm_acc'], 'k--', label='mlm_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b67a939",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b2776",
   "metadata": {},
   "source": [
    "- DLthon에서 사용했던 bert모델을 직접 정의 해보고 사전 훈련까지 해보니까 왜 문맥을 이해 할 수 있으며, 분류에 적합한지 자세히 알게 됨\n",
    "\n",
    "\n",
    "- 또한 huggingface에 올라온 bert 모델의 성능과 직접 제작한 모델의 성능 차이를 볼때 어마어마한 데이터를 학습해야 그나마 비슷해질 거 같단 생각이 듦\n",
    "\n",
    "\n",
    "- 트랜스포머 파생 모델을 지금까지 GPT, Bert 두가지를 제작 해봤는데 제작 난이도는 Bert가 더 어려웠던거 같음!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
