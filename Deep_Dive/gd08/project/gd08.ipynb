{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "757025f6",
   "metadata": {},
   "source": [
    "# STEP 0. 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "340a5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "from datasets import load_metric\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, TFBertForSequenceClassification\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from datasets import Dataset, DatasetDict\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530052ce",
   "metadata": {},
   "source": [
    "# STEP 1. NSMC 데이터 분석 및 Huggingface dataset 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeb83b4",
   "metadata": {},
   "source": [
    "데이터셋은 깃허브에서 다운"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5898b6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getenv('HOME')+'/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/'\n",
    "\n",
    "train = pd.read_table(path + 'ratings_train.txt')\n",
    "test = pd.read_table(path + 'ratings_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0586bb",
   "metadata": {},
   "source": [
    "# STEP 2. klue/bert-base model 및 tokenizer 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e7945f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4fb432d014c4a119dc12a84b6aab800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c649173e5ef54ef582789f3aacfb061f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e88c8812bf0e4101a9565723e15211ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/243k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3a8f978f5444079ac50545e828ab65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fdd001facf4d5b9a0fe26f8453475a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f72f1827e843f2848bb9ee2b1f7c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/424M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "huggingface_model_path = \"klue/bert-base\"\n",
    "huggingface_tokenizer = AutoTokenizer.from_pretrained(huggingface_model_path)\n",
    "huggingface_model = AutoModelForSequenceClassification.from_pretrained(huggingface_model_path, num_labels = 2)\n",
    "# 가중치 고정\n",
    "huggingface_model.bert.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae46826",
   "metadata": {},
   "source": [
    "# STEP 3. 위에서 불러온 tokenizer으로 데이터셋을 전처리하고, model 학습 진행해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfaa5be",
   "metadata": {},
   "source": [
    "결측치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9594300a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d78a30f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    3\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c246e8e7",
   "metadata": {},
   "source": [
    "결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5220d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70c2836c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(train.duplicated().sum())\n",
    "print(test.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ea931",
   "metadata": {},
   "source": [
    "max_len을 정하기 위한 길이 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e5f019d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f4015c4b3d4dee9f5b6b7b1d2a1b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/149995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3547e39510474fb65c64c1b7fb1625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train의 최소 길이 : 1\n",
      "train의 최대 길이 : 140\n",
      "train의 평균 길이 : 20.276189206306878\n",
      "test의 최소 길이 : 1\n",
      "test의 최대 길이 : 120\n",
      "test의 평균 길이 : 20.360981658899533\n"
     ]
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "train_len = [len(huggingface_tokenizer.tokenize(s)) for s in tqdm(train['document'])]\n",
    "test_len = [len(huggingface_tokenizer.tokenize(s)) for s in tqdm(test['document'])]\n",
    "\n",
    "print('train의 최소 길이 : {}'.format(np.min(train_len)))\n",
    "print('train의 최대 길이 : {}'.format(np.max(train_len)))\n",
    "print('train의 평균 길이 : {}'.format(np.mean(train_len)))\n",
    "print('test의 최소 길이 : {}'.format(np.min(test_len)))\n",
    "print('test의 최대 길이 : {}'.format(np.max(test_len)))\n",
    "print('test의 평균 길이 : {}'.format(np.mean(test_len)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f027e67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e111a901af2642998a95e461e608af6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/149995 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 20 이하인 샘플의 비율: 0.9365645521517384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f20dcee96144dc281f736ef2b413046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49997 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 20 이하인 샘플의 비율: 0.935416124967498\n"
     ]
    }
   ],
   "source": [
    "# max_len 길이를 선택했을 때, 얼마나 많은 샘플들을 자르지 않고\n",
    "# 포함할 수 있는지 통계로 확인하는 함수\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in tqdm(nested_list):\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "            \n",
    "below_threshold_len(20, train['document'])\n",
    "below_threshold_len(20, test['document'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec8101",
   "metadata": {},
   "source": [
    "max_len이하 데이터만 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6627c49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 20\n",
    "train = train[train['document'].apply(lambda x: len(huggingface_tokenizer.tokenize(x)) <= max_len)]\n",
    "test = test[test['document'].apply(lambda x: len(huggingface_tokenizer.tokenize(x)) <= max_len)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b48d2ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98243\n",
      "32675\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e841d6b",
   "metadata": {},
   "source": [
    "데이터를 DatasetDict으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58c5bbde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 98243\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'document', 'label'],\n",
      "        num_rows: 32675\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Hugging Face의 Dataset으로 변환\n",
    "train_dataset = Dataset.from_pandas(train)\n",
    "test_dataset = Dataset.from_pandas(test)\n",
    "\n",
    "# DatasetDict로 결합\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n",
    "dataset = dataset.remove_columns([\"__index_level_0__\"])\n",
    "\n",
    "# 결과 확인\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312bba6f",
   "metadata": {},
   "source": [
    "토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "554a9010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d276b635754312b8b118562d74ce7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/99 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82d654f3306437a8bc0a4de1d09110e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transform(data):\n",
    "    return huggingface_tokenizer(\n",
    "        data['document'],\n",
    "        truncation = True,\n",
    "        padding = 'max_length',\n",
    "        return_token_type_ids = False,\n",
    "        )\n",
    "\n",
    "dataset = dataset.map(transform, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3cf6a7",
   "metadata": {},
   "source": [
    "데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca9ffe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset['train']\n",
    "# dataset['test'] 내부를 다시 train과 test셋으로 나눔\n",
    "val_test_split = dataset['test'].train_test_split(test_size=0.2)\n",
    "\n",
    "val_dataset = val_test_split['train']\n",
    "test_dataset = val_test_split['test'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1fe0d2",
   "metadata": {},
   "source": [
    "train argument 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e237eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.getenv('HOME')+'/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08'\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir,                                         # output이 저장될 경로\n",
    "    evaluation_strategy=\"epoch\",           #evaluation하는 빈도\n",
    "    learning_rate = 2e-5,                         #learning_rate\n",
    "    per_device_train_batch_size = 14,   # 각 device 당 batch size\n",
    "    per_device_eval_batch_size = 14,    # evaluation 시에 batch size\n",
    "    num_train_epochs = 3,                     # train 시킬 총 epochs\n",
    "    weight_decay = 0.01,                        # weight decay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a67ba41",
   "metadata": {},
   "source": [
    "compute_metrics 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afd95da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05b79d3fb9f6444198ef9d8e469f44d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):    \n",
    "    predictions,labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a941118",
   "metadata": {},
   "source": [
    "Trainer 정의후 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af385376",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running training *****\n",
      "  Num examples = 98243\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 14\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 14\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 21054\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21054' max='21054' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21054/21054 8:08:21, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.276900</td>\n",
       "      <td>0.280597</td>\n",
       "      <td>0.887911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.310845</td>\n",
       "      <td>0.891584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.411153</td>\n",
       "      <td>0.893152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-1000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-1000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-1000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-1500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-1500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-1500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-2000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-2000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-2000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-2500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-2500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-2500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-3000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-3000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-3000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-3500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-3500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-3500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-4000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-4000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-4000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-4500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-4500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-4500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-5000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-5000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-5000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-5500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-5500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-5500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-6000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-6000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-6000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-6500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-6500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-6500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-7000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-7000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-7000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 26140\n",
      "  Batch size = 14\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-7500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-7500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-7500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-8000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-8000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-8000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-8500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-8500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-8500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-9000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-9000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-9000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-9500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-9500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-9500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-10000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-10000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-10000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-10500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-10500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-10500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-11000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-11000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-11000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-11500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-11500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-11500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-12000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-12000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-12000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-12500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-12500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-12500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-13000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-13000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-13000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-13500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-13500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-13500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-14000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-14000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-14000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 26140\n",
      "  Batch size = 14\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-14500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-14500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-14500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-15000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-15000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-15000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-15500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-15500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-15500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-16000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-16000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-16000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-16500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-16500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-16500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-17000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-17000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-17000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-17500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-17500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-17500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-18000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-18000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-18000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-18500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-18500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-18500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-19000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-19000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-19000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-19500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-19500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-19500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-20000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-20000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-20000/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-20500\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-20500/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-20500/pytorch_model.bin\n",
      "Saving model checkpoint to /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-21000\n",
      "Configuration saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-21000/config.json\n",
      "Model weights saved in /aiffel/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd08/checkpoint-21000/pytorch_model.bin\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 26140\n",
      "  Batch size = 14\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21054, training_loss=0.22621684107468362, metrics={'train_runtime': 29303.7154, 'train_samples_per_second': 10.058, 'train_steps_per_second': 0.718, 'total_flos': 7.754645823519744e+16, 'train_loss': 0.22621684107468362, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=huggingface_model,           # 학습시킬 model\n",
    "    args=training_arguments,           # TrainingArguments을 통해 설정한 arguments\n",
    "    train_dataset=train_dataset,    # training dataset\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d05a081",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65ab8143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: document, id.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 6535\n",
      "  Batch size = 14\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='467' max='467' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [467/467 03:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.41729044914245605,\n",
       " 'eval_accuracy': 0.8915072685539404,\n",
       " 'eval_runtime': 219.1384,\n",
       " 'eval_samples_per_second': 29.821,\n",
       " 'eval_steps_per_second': 2.131,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a8a68b",
   "metadata": {},
   "source": [
    "# STEP 4. Bucketing을 적용하여 학습시키고, STEP 3의 결과와의 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012291ec",
   "metadata": {},
   "source": [
    "데이터 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe5cb522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset nsmc (/aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0eb6c426ed48dd88502af140907da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('e9t/nsmc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c834b64",
   "metadata": {},
   "source": [
    "데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3611c2aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached split indices for dataset at /aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-d09880cac8a4b036.arrow and /aiffel/.cache/huggingface/datasets/e9t___nsmc)/default/1.1.0/bfd4729bf1a67114e5267e6916b9e4807010aeb238e4a3c2b95fbfa3a014b5f3/cache-603f7bbd9708353c.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train']\n",
    "val_test_split = dataset['test'].train_test_split(test_size=0.2)\n",
    "\n",
    "val_dataset = val_test_split['train']\n",
    "test_dataset = val_test_split['test'] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a299a974",
   "metadata": {},
   "source": [
    "input, target 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f12b3d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x = train_dataset['document']\n",
    "val_x = val_dataset['document']\n",
    "test_x = test_dataset['document']\n",
    "train_y = train_dataset['label']\n",
    "val_y = val_dataset['label']\n",
    "test_y = test_dataset['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159053eb",
   "metadata": {},
   "source": [
    "토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab1b4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "    return huggingface_tokenizer(\n",
    "        data,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "train_encodings = transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca24eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encodings = transform(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc58f717",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encodings = transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c329321c",
   "metadata": {},
   "source": [
    "bucketing 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ae89d894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bucketed_dataset(encodings, labels):\n",
    "    # RaggedTensor로 생성하여 가변 길이 허용\n",
    "    input_ids = tf.ragged.constant(encodings['input_ids'])\n",
    "    attention_mask = tf.ragged.constant(encodings['attention_mask'])\n",
    "    \n",
    "    # 레이블을 Tensor로 변환\n",
    "    labels = tf.constant(labels)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((\n",
    "        {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "        },\n",
    "        labels\n",
    "    ))\n",
    "    \n",
    "    # 배치 처리 및 RaggedTensor를 텐서로 변환\n",
    "    def map_to_tensor(inputs, label):\n",
    "        return (\n",
    "            {\n",
    "                'input_ids': tf.convert_to_tensor(inputs['input_ids']),\n",
    "                'attention_mask': tf.convert_to_tensor(inputs['attention_mask']),\n",
    "            },\n",
    "            label\n",
    "        )\n",
    "\n",
    "    # 각 요소를 텐서로 변환\n",
    "    dataset = dataset.map(map_to_tensor)\n",
    "\n",
    "    # 패딩 및 버킷 적용\n",
    "    def element_length_func(inputs, label):\n",
    "        return tf.shape(inputs['input_ids'])[0]  # 길이 반환\n",
    "    \n",
    "    padding_values = (\n",
    "        {\n",
    "            'input_ids': tf.constant(0, dtype=tf.int32),\n",
    "            'attention_mask': tf.constant(0, dtype=tf.int32),\n",
    "        },\n",
    "        tf.constant(0, dtype=tf.int32)  # 레이블 패딩\n",
    "    )\n",
    "\n",
    "    bucketed_dataset = dataset.bucket_by_sequence_length(\n",
    "        element_length_func=element_length_func,\n",
    "        bucket_boundaries=[20, 50, 80, 110, 140],\n",
    "        bucket_batch_sizes=[14, 11, 8, 5, 2, 1],\n",
    "        padding_values=padding_values,\n",
    "        drop_remainder=True\n",
    "    )\n",
    "    \n",
    "    return bucketed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d06dbaf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bucketed_train_dataset = create_bucketed_dataset(train_encodings, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2494135",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketed_val_dataset = create_bucketed_dataset(val_encodings, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1ff0b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucketed_test_dataset = create_bucketed_dataset(test_encodings, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449dc517",
   "metadata": {},
   "source": [
    "klue-bert를 FT모델로 불러옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7061d636",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "huggingface_model = TFBertForSequenceClassification.from_pretrained(huggingface_model_path, num_labels = 2, from_pt=True)\n",
    "huggingface_model.bert.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63095c4",
   "metadata": {},
   "source": [
    "모델 컴파일 및 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "434a0b8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "12538/12538 [==============================] - 675s 53ms/step - loss: 0.4901 - accuracy: 0.7757 - val_loss: 0.4308 - val_accuracy: 0.8085\n",
      "Epoch 2/3\n",
      "12538/12538 [==============================] - 657s 52ms/step - loss: 0.4360 - accuracy: 0.8031 - val_loss: 0.4167 - val_accuracy: 0.8124\n",
      "Epoch 3/3\n",
      "12538/12538 [==============================] - 656s 52ms/step - loss: 0.4269 - accuracy: 0.8083 - val_loss: 0.4108 - val_accuracy: 0.8145\n"
     ]
    }
   ],
   "source": [
    "# 모델 컴파일\n",
    "huggingface_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),  # learning_rate\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # loss function\n",
    "    metrics=['accuracy']  # 평가 지표\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "history = huggingface_model.fit(\n",
    "    bucketed_train_dataset,\n",
    "    validation_data=bucketed_val_dataset,  # 검증 데이터셋\n",
    "    epochs=3,  # 총 epochs\n",
    "    verbose=1,  # 훈련 로그 출력\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True),  # 조기 종료 설정\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa26450",
   "metadata": {},
   "source": [
    "모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba33f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "839/839 [==============================] - 34s 41ms/step - loss: 0.4011 - accuracy: 0.8200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40109875798225403, 0.8200220465660095]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_model.evaluate(bucketed_test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d780afd",
   "metadata": {},
   "source": [
    "## 다른 전처리 O / Bucketing X  vs. 다른 전처리 X / Bucketing O\n",
    "\n",
    "- 다른 전처리 O / Bucketing X -> A\n",
    "    - 훈련 시간: 8:08:21\n",
    "    - Training Loss: 0.148800\n",
    "    - Validation Loss: 0.411153\n",
    "    - Accuracy: 0.893152\n",
    "    - eval_loss: 0.31855401396751404\n",
    "    - eval_accuracy: 0.891354246365723\n",
    "    \n",
    "---\n",
    "    \n",
    "- 다른 전처리 X / Bucketing O -> B\n",
    "    - 훈련 시간: 00:33:08\n",
    "    - Training Loss: 0.4269\n",
    "    - Validation Loss: 0.4108\n",
    "    - Training Accuracy: 0.8083\n",
    "    - Validation Accuracy: 0.8145\n",
    "    - eval_loss: 0.40109875798225403\n",
    "    - eval_accuracy: 0.8200220465660095\n",
    "  \n",
    "---  \n",
    "---\n",
    "\n",
    "- B보단 A가 성능면에선 우수함\n",
    "    - 하지만 시간이 너무 오래 걸림\n",
    "- B는 시간 대비 성능이 우수하다고 볼 수 있음\n",
    "    - epoch를 더 늘리면 성능이 좋아질 가능성이..?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7d5748",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf959f1c",
   "metadata": {},
   "source": [
    "- DLthon때 똑같이 klue-bert를 사용\n",
    "    - 그 당시에는 Trainer를 어떻게 사용하는지 몰라 ft모델로 불러와 사용 했었음\n",
    "    - 이번 프로젝트를 통해 Trainer의 사용법을 제대로 익힌거 같아 좋음\n",
    "    \n",
    "    \n",
    "- Bucketing이라는 기법을 프로젝트 하면서 처음 접했음\n",
    "    - 훈련 시간이 획기적으로 줄어들어 맘에 듬\n",
    "    - 성능은 epoch라던가 하이퍼파라미터 튜닝, 데이터셋 전처리 나 추가를 통해 향상 시킬 수 있지 않을까 생각이 듬"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
