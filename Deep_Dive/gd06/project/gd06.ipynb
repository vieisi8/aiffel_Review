{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8b2f0bf",
   "metadata": {},
   "source": [
    "# Step 0. 필요한 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a87fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88350678",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e4d682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12시 땡!   하루가 또 가네요.      0\n",
       "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
       "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
       "4          PPL 심하네   눈살이 찌푸려지죠.      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = os.getenv('HOME')+'/aiffel/transformer_chatbot/data'\n",
    "\n",
    "data = pd.read_csv(file_path+'/ChatbotData.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c73ca5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = data['Q']\n",
    "answers = data['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ac30a",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23baeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \n",
    "    # 소문자로 치환\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # 한글, 영어, 숫자, 구두점 외 제거\n",
    "    sentence = re.sub(r\"[^가-힣ㄱ-ㅎㅏ-ㅣa-zA-Z0-9.,!? ]\", \" \", sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27825cdd",
   "metadata": {},
   "source": [
    "# Step 3. 데이터 토큰화"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "27d8507f",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)\n",
    "\n",
    "- 위 결과를 확인해 토큰 개수가 많지 않다는 인사이트를 얻음\n",
    "\n",
    "    -> max_len을 지정해 일정 길이 이상인 데이터 제외를 하지 않을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d7c1ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_corpus(enc, dec):\n",
    "    \n",
    "    # 데이터 정제 및 토큰화\n",
    "    mecab_enc_corpus = []\n",
    "    mecab_dec_corpus = []\n",
    "\n",
    "    for x in tqdm(enc, desc='소스 데이터 정제 및 토큰화'):\n",
    "        clean_sentence = preprocess_sentence(x)\n",
    "        mecab_enc_corpus.append(mecab.morphs(clean_sentence))\n",
    "\n",
    "    for x in tqdm(dec, desc='타켓 데이터 정제 및 토큰화'):\n",
    "        clean_sentence = preprocess_sentence(x)\n",
    "        mecab_dec_corpus.append(mecab.morphs(clean_sentence))\n",
    "    \n",
    "    \n",
    "    # 데이터프레임화\n",
    "    df = pd.DataFrame({\n",
    "        \"Q\": [' '.join(map(str, q)) for q in mecab_enc_corpus],  # 리스트 요소를 문자열로 변환\n",
    "        \"A\": [' '.join(map(str, a)) for a in mecab_dec_corpus]   # 리스트 요소를 문자열로 변환\n",
    "    })\n",
    "    \n",
    "    # 각 데이터 중복 제거 (리스트를 문자열로 변환 후 중복 제거)\n",
    "    df.drop_duplicates(subset='Q', inplace=True)\n",
    "    df.drop_duplicates(subset='A', inplace=True)\n",
    "    \n",
    "    # 중복 제거 후 다시 리스트로 변환\n",
    "    que_corpus = [q.split() for q in df['Q']]  # 문자열을 다시 리스트로 변환\n",
    "    ans_corpus = [a.split() for a in df['A']]  # 문자열을 다시 리스트로 변환\n",
    "    \n",
    "    return que_corpus, ans_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee7e8e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbfdced39ded4d87b30a9287028f846a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "소스 데이터 정제 및 토큰화:   0%|          | 0/11823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a301499c1c4ac5a2bbe8a513499aa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "타켓 데이터 정제 및 토큰화:   0%|          | 0/11823 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 정제 및 토큰화 수행\n",
    "que_corpus, ans_corpus = build_corpus(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d4781d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7674\n",
      "7674\n"
     ]
    }
   ],
   "source": [
    "print(len(que_corpus))\n",
    "print(len(ans_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d93246",
   "metadata": {},
   "source": [
    "# Step 4. Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec135a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim==3.8.3 in /opt/conda/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.21.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (5.2.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.9/site-packages (from gensim==3.8.3) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5f14d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89493f2f603a49a2a6c57480029ffbe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "데이터  증강중:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c698b17f0084a578ab2fc24b3161318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "소스 데이터 증강:   0%|          | 0/7674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf1c81108ea42e0a09cc65ed248a986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "타켓 데이터 증강:   0%|          | 0/7674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d714abb404484ae393eb6eab17fdad84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "소스 데이터 증강:   0%|          | 0/7674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38aacc475f24438869b486ed82e2410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "타켓 데이터 증강:   0%|          | 0/7674 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "def load_embeddings(filepath):\n",
    "    model = Word2Vec.load(model_path)\n",
    "    return model\n",
    "\n",
    "def lexical_sub(sentence, model, topn=5):\n",
    "    \"\"\"\n",
    "    주어진 문장에서 각 단어를 유사한 단어로 대체하여 새로운 문장 생성.\n",
    "    :param sentence: 원본 문장 (list of tokens)\n",
    "    :param model: Word2Vec 임베딩 모델\n",
    "    :param topn: 대체 후보로 사용할 상위 유사 단어 개수\n",
    "    :return: 대체된 단어로 구성된 문장\n",
    "    \"\"\"\n",
    "    new_sentence = []\n",
    "    \n",
    "    for word in sentence:\n",
    "        # 모델에 해당 단어가 있는지 확인\n",
    "        if word in model.wv:\n",
    "            # 해당 단어와 유사한 단어 리스트에서 무작위로 선택\n",
    "            similar_words = model.wv.most_similar(word, topn=topn)\n",
    "            substitute_word = random.choice(similar_words)[0]\n",
    "            new_sentence.append(substitute_word)\n",
    "        else:\n",
    "            # 모델에 단어가 없으면 원본 단어 사용\n",
    "            new_sentence.append(word)\n",
    "    \n",
    "    return new_sentence\n",
    "\n",
    "# 한국어로 사전 훈련된 Embedding 모델 load\n",
    "model_path = os.getenv('HOME') + '/aiffel/aiffel/AIFFEL_quest_rs/GoingDeeper/Gd06/ko.bin'\n",
    "model = load_embeddings(model_path)\n",
    "\n",
    "aug_que_corpus = []\n",
    "aug_ans_corpus = []\n",
    "\n",
    "for x in tqdm(range(2), desc='데이터  증강중'):\n",
    "    for sentence in tqdm(que_corpus, desc='소스 데이터 증강'):\n",
    "        aug_que_corpus.append(lexical_sub(sentence, model))\n",
    "    for sentence in tqdm(ans_corpus, desc='타켓 데이터 증강'):\n",
    "        aug_ans_corpus.append(lexical_sub(sentence, model))\n",
    "\n",
    "# 3배로 증강된 데이터셋을 질문과 답변을 나누어서 저장\n",
    "augmented_que_corpus = (\n",
    "    [aug_que for aug_que in aug_que_corpus] +\n",
    "    [que for que in que_corpus] +\n",
    "    [que for que in que_corpus]\n",
    ")\n",
    "\n",
    "augmented_ans_corpus = (\n",
    "    [ans for ans in ans_corpus] +\n",
    "    [aug_ans for aug_ans in aug_ans_corpus] +\n",
    "    [ans for ans in ans_corpus]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "100ade1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30696\n",
      "30696\n"
     ]
    }
   ],
   "source": [
    "print(len(augmented_que_corpus))\n",
    "print(len(augmented_ans_corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac630b17",
   "metadata": {},
   "source": [
    "# Step 5. 데이터 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eead684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bb70aed13545fba3d4eae5b76da8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "타켓 데이터 <start> 토큰과 <end> 토큰 추기:   0%|          | 0/30696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# <start> 토큰과 <end> 토큰 추가\n",
    "\n",
    "token_added_augmented_ans_corpus = []\n",
    "\n",
    "for sentence in tqdm(augmented_ans_corpus, desc='타켓 데이터 <start> 토큰과 <end> 토큰 추기'):\n",
    "    token_added_augmented_ans_corpus.append([\"<start>\"] + sentence + [\"<end>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bde98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a60692b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62cac0bbbaf47e887bf3fa0f5a0fa28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "데이터 통합:   0%|          | 0/30696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e426398474d241918abe1b1809bb6c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "데이터 통합:   0%|          | 0/30696 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 단어 사전 구축, 벡터화\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for x in tqdm(range(len(augmented_que_corpus)), desc='데이터 통합'):\n",
    "    corpus.append(augmented_que_corpus[x])\n",
    "    \n",
    "for x in tqdm(range(len(augmented_ans_corpus)), desc='데이터 통합'):\n",
    "    corpus.append(token_added_augmented_ans_corpus[x])\n",
    "\n",
    "#토큰화\n",
    "corpus, tokenizer = tokenize(corpus)\n",
    "\n",
    "# 통합한 데이터 분리\n",
    "enc_train = corpus[:30696]\n",
    "dec_train = corpus[30696:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d061c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30696\n",
      "30696\n"
     ]
    }
   ],
   "source": [
    "print(len(enc_train))\n",
    "print(len(dec_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51c39d",
   "metadata": {},
   "source": [
    "# Step 6. 훈련하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85866d26",
   "metadata": {},
   "source": [
    "Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b575a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding 구현\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, (2*(i//2)) / np.float32(d_model))\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "\n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ee0fe1",
   "metadata": {},
   "source": [
    "마스크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04a0838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask  생성하기\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_lookahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "\n",
    "    dec_lookahead_mask = generate_lookahead_mask(tgt.shape[1])\n",
    "    dec_tgt_padding_mask = generate_padding_mask(tgt)\n",
    "    dec_mask = tf.maximum(dec_tgt_padding_mask, dec_lookahead_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd5ac7",
   "metadata": {},
   "source": [
    "Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e189103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi Head Attention 구현\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "\n",
    "    def split_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "                        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "            \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b18bb5",
   "metadata": {},
   "source": [
    "Position-wise Feed Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ac33bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Position-wise Feed Forward Network 구현\n",
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc2(out)\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204c4513",
   "metadata": {},
   "source": [
    "Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0a46b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder의 레이어 구현\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb20f4b",
   "metadata": {},
   "source": [
    "Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df6aa9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 레이어 구현\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        '''\n",
    "        Masked Multi-Head Attention\n",
    "        '''\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        '''\n",
    "        Multi-Head Attention\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        # Q, K, V 순서에 주의하세요!\n",
    "        out, dec_enc_attn = self.enc_dec_attn(Q=out, K=enc_out, V=enc_out, mask=dec_enc_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        '''\n",
    "        Position-Wise Feed Forward Network\n",
    "        '''\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6756c",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b44fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder 구현\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "    \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f88a17b",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6313c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder 구현\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "    def call(self, x, enc_out, dec_enc_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, dec_enc_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7e9643",
   "metadata": {},
   "source": [
    "Transformer 전체 모델 조립"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea20d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                    n_layers,\n",
    "                    d_model,\n",
    "                    n_heads,\n",
    "                    d_ff,\n",
    "                    src_vocab_size,\n",
    "                    tgt_vocab_size,\n",
    "                    pos_len,\n",
    "                    dropout=0.2,\n",
    "                    shared_fc=True,\n",
    "                    shared_emb=False):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "\n",
    "        if shared_emb:\n",
    "            self.enc_emb = self.dec_emb = \\\n",
    "            tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        else:\n",
    "            self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "            self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared_fc = shared_fc\n",
    "\n",
    "        if shared_fc:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared_fc: out *= tf.math.sqrt(self.d_model)\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, dec_enc_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, dec_enc_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addbcfb6",
   "metadata": {},
   "source": [
    "Masking 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08044d72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def generate_padding_mask(seq):\\n    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\\n    return seq[:, tf.newaxis, tf.newaxis, :]\\n\\ndef generate_causality_mask(src_len, tgt_len):\\n    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\\n    return tf.cast(mask, tf.float32)\\n\\ndef generate_masks(src, tgt):\\n    enc_mask = generate_padding_mask(src)\\n    dec_enc_mask = generate_padding_mask(src)\\n    dec_mask = generate_padding_mask(tgt)\\n\\n    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\\n    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\\n\\n    return enc_mask, dec_enc_mask, dec_mask'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1641ab",
   "metadata": {},
   "source": [
    "모델 인스턴스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "38db5e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주어진 하이퍼파라미터로 Transformer 인스턴스 생성\n",
    "n_layers = 2\n",
    "d_model = 1024\n",
    "n_heads = 8\n",
    "d_ff = 2048\n",
    "src_vocab_size = tgt_vocab_size = len(tokenizer.word_index) + 1\n",
    "pos_len = 256\n",
    "dropout=0.3\n",
    "\n",
    "transformer = Transformer(\n",
    "    n_layers,\n",
    "    d_model,\n",
    "    n_heads,\n",
    "    d_ff,\n",
    "    src_vocab_size,\n",
    "    tgt_vocab_size,\n",
    "    pos_len,\n",
    "    dropout,\n",
    "    shared_fc=True,\n",
    "    shared_emb=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1417c916",
   "metadata": {},
   "source": [
    "Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c475de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Scheduler 구현\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90ad088",
   "metadata": {},
   "source": [
    "Learning Rate & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7b43790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate 인스턴스 선언 & Optimizer 구현\n",
    "learning_rate = LearningRateScheduler(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                        beta_1=0.9,\n",
    "                                        beta_2=0.98, \n",
    "                                        epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001fba5c",
   "metadata": {},
   "source": [
    "Loss Function 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84c12134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function 정의\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de18dac6",
   "metadata": {},
   "source": [
    "Train Step 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5d916d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 정의\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    tgt_in = tgt[:, :-1]  # Decoder의 input\n",
    "    gold = tgt[:, 1:]     # Decoder의 output과 비교하기 위해 right shift를 통해 생성한 최종 타겟\n",
    "\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a78d7c",
   "metadata": {},
   "source": [
    "번역 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a84eab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(sequence):\n",
    "    return ' '.join([tokenizer.index_word[index] for index in sequence if index in tokenizer.index_word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "588fbabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tokens, model,tokenizer):\n",
    "    max_len = 40\n",
    "    \n",
    "    tokens = preprocess_sentence(tokens)\n",
    "    tokens = tokenizer.texts_to_sequences(tokens)\n",
    "    \n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences(tokens,\n",
    "                                                           maxlen=max_len,\n",
    "                                                           padding='post')\n",
    "    ids = []\n",
    "    output = tf.expand_dims([tokenizer.word_index['<start>']], 0)   \n",
    "    for i in range(max_len):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                      output,\n",
    "                                      enc_padding_mask,\n",
    "                                      combined_mask,\n",
    "                                      dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tokenizer.word_index['<end>'] == predicted_id:\n",
    "            result = decode_sequence(ids)  \n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "        \n",
    "    result = decode_sequence(ids)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4599470",
   "metadata": {},
   "source": [
    "훈련 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "886be685",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe08e1831f3547dea8367f2878e6be56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd50228c3d74221a5195ed486524541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 은 은 듯 봐요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 기쁨 기쁨 않 않 않 으니\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 기쁨 역시 역시 이란 ㅂ시다 ...\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니 아니\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd0c16dca3454cdbb050d3d40d44a23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad1069e136f44489fa7c1fc3a1f825a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 좋 은 사람 들 이 에요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 저 도 좋 아 가 있 어요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 오늘 를 보 세요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 저 도 있 어요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9658f8815904b329335f2953aad4ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29da37cbecf14bc1b9a5ce67a46a9a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 그럴 때 는 것 예요 는데\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 태현\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 나쁘 이란 나쁘 이란 나쁘 이란 나쁘 이란 나쁘 지요 ...\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 저 는 편 이 에요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027a4607106b4f1a914b0c9140dbbadf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7811ebe3f474dd28356589ebc893c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 어떡 들 을 해야 할 수 있 어요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 태현 때문 몇 아모리 해요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 나쁘 무수히 백만 해요 박영규\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 저 는 편 이 아니 었 나 봐요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "228a9ee2a5a7454db66329f87ee3c271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8de9dbb04c34be1a665066e04f6d501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 널리 머물 봐요 는데\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 즐거운 장시간 수가 이루어지 더군요 는데\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 한 번 든 한 번 든 한 번 든 한 번 든 한 번 든 한 번 든 한 번 든 한 게 해요\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 고향 그러하 ㄴ다 으므로 좋아지 이란 확정 그러 ㄴ다 들여다보 일일이 는데\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d572db9f7094942ade50f110efab778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d33dc65a35a4fa588be69e7050d2cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 어찌 퀼 를 지키 는다는 포졸 를 지키 는다는 포졸 를 지키 아서요 는데\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 세요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 나쁘 이란 포졸 으로 ㄴ지요 ...\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 저 는 편 이 아니 싶 었 으면 싶 는데요 으니\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e06b854e9547e09433c69c39044cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad5e4307b65d4f47823cf11308f92142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 그래도 야쓰시 때 보다 괜찮 아요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 간격 아니 바트 사루 수가 ㅂ니다 박영규\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 가슴 풀어쓰 나쁘 이란 뭐\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 돈 이 아니 돈 이 에요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eec3a40e8cca4cab95674ddb65c9a21d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b36d166e634054bb3970bc4df854bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 죄인 아니 머물 는데 아쉽 아서요 으나\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 세요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 생각나 게끔 하고 게끔 하고 게끔 하고 게끔 해요 ...\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 고향 그러하 안가 나쁘 이란 월과 그러하 ㅂ니까 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1a59f9a78f04046bd024349dcb52c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a14d41ac95c48aebc2937129290f7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 그래도 슬프 네요 ...\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 간격 때문 분경 집시 이상\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 기의 게끔 갑자기 갑자기 ㅂ시다 ...\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 다를 것 으므로 와 다를 것 예요 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a283221b4a4fa091da8ca5ac8d22e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c89002970d34395a1ed3b339f70aa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 부끄러운 감정 이 어떡 할 때 보다 그래요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 간격 때문 있다 사루 봐요 박영규\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 자세히 놀 일일이 으나\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 좋아지 이란 월과 그러하 ㅂ니까 는데\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11c46a8bc4774e7ba3e9be4c153afe76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f130309e3a45d0a39251cb13e6c85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 때론 정확히 밝혀 봐요 는데\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 코리 유혹 잦 ㅂ니다 으나\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 시키 게끔 시키 지만 영혼 으로 있다 는데요 박영규\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 바구니 내기 다를 것 비슷 므로 바구니 내기 다를 것 비슷 구요 는데\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94edae5a8254466bb00eac6a6496c5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b09e4d6f0e74646aa30a9ba6fe8c9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 바쁜가 봐요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 못 자 세요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 지금 은 우세요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 돈 은 아름답 므로 나쁘 싶 네요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4976e370cb924ae18d0b2c71571319b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c11f8992f4547f0bca7a2c49f989d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 구축 으로 으므로 당신 구축 으로 아서요 으나\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 간격 아니 있음 타 머지않 타 봐요 박영규\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 생각나 기 도 하 겠 어요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 제 한테 라면 고향 로도 다를 것 같 아요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54df4b93bcb04ec4a927a76aa3d5acbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8151480a194827b240b23431556916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 그래도 사랑 할 수 있 죠 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 제 가 드리 고 싶 네요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 설정 한두 사실 으로 았 타 봐요 ...\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 좋 은 결정 이 아니 에요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35442bb8b3b7401c965c7161b1b96008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f74489c73842f999bec7ad482d3755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 살아가 거든요 는데 멋지 어도 나쁘 구요 는데\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 간격 그렇 있음 였 나의 봅니다 는데\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 생각나 갑자기 생각나 갑자기 생각나 갑자기 생각나 갑자기 생각나 ㅂ시다\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 집이 줌 므로 나쁘 었 군요 는데\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e00e52958fd4f0a942cd8d3dcc75c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f79c688b8a74a3dabd739b9e66f3ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 귀찮 봐요 으나\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 나쁜 분 에게 물 어 보 세요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 생각나 기 도 해요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 다섯 찾아가 들여다보 므로 그리울 말로 아니 ㄴ지요 으나\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d4bc45bfae4089bbc66ad22706fb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0879df85c0b141588dc39a226517f9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 때론 은 때론 노력 하 는 사람 인가 봐요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 좀더 던 펠 것 예요\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 만남 꾀하 게끔 만남 으로서 만남 한두 무척 만남 으로서 만남 으로서 용이 해요 ...\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 제 그럼 오자키 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "561c62491cc341188edd79ec68ed50d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ce715fc628409696d8483890a6dbdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 색다른 걸 어 보 세요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 좀 더 찾 ㅂ시오 ...\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 생각나 게 사 는 게 갑자기 생각나 세요 .\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 저 에게 받 고 싶 은 위 로 만들 어 에게 좋 은 거 같 아요 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6e291e6c8840b1a0f91b4c92afed9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "657c70e8b3ec482abcb8456ca81c762b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 색다른 걸 드셔 보 세요 .\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 만 있 어도 만 있 습니다 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 잊어버리 ㅂ시오\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 마요 ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f9a9b1054b4e449bb7f0d4bbf67124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20/20:   0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581d92befcd94c9ab703b4b4e654bedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "예문의 답변 생성중:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 지루하다, 놀러가고 싶어.\n",
      "Predicted translation: 어떡 시키 아서 좋아지 예기 모르 네요 으나\n",
      "Input: 오늘 일찍 일어났더니 피곤하다.\n",
      "Predicted translation: 잘 모르 고 있 는 만 해요 .\n",
      "Input: 간만에 여자친구랑 데이트 하기로 했어.\n",
      "Predicted translation: 갑자기 읽 ㅂ시오 박영규\n",
      "Input: 집에 있는다는 소리야.\n",
      "Predicted translation: 집이 주위 것들 오자키 캐치\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 128\n",
    "EPOCHS = 20\n",
    "\n",
    "model_list = []\n",
    "result_list_lsit = []\n",
    "\n",
    "examples = [\n",
    "            \"지루하다, 놀러가고 싶어.\",\n",
    "            \"오늘 일찍 일어났더니 피곤하다.\",\n",
    "            \"간만에 여자친구랑 데이트 하기로 했어.\",\n",
    "            \"집에 있는다는 소리야.\"\n",
    "]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    result_list = []\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list, desc=f'Epoch {epoch+1}/{EPOCHS}')\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "\n",
    "    for example in tqdm(examples,desc = '예문의 답변 생성중'):\n",
    "        result = translate(example, transformer, tokenizer)\n",
    "        result_list.append(result)\n",
    "        \n",
    "        print('Input: %s' % (example))\n",
    "        print('Predicted translation: {}'.format(result))\n",
    "        \n",
    "    model_list.append(transformer.get_weights())\n",
    "    result_list_lsit.append(result_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb023621",
   "metadata": {},
   "source": [
    "# Step 7. 성능 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51e68d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference],\n",
    "                         candidate,\n",
    "                         weights=weights,\n",
    "                         smoothing_function=SmoothingFunction().method1)  # smoothing_function 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "416826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu_single(src, tgt):\n",
    "    max_len = 40\n",
    "    \n",
    "    src = preprocess_sentence(src)\n",
    "    src_seq = tokenizer.texts_to_sequences([src])  # 리스트로 감싸줍니다\n",
    "    \n",
    "    src_seq = tf.keras.preprocessing.sequence.pad_sequences(src_seq,\n",
    "                                                            maxlen=max_len,\n",
    "                                                            padding='post')\n",
    "    \n",
    "    tgt = preprocess_sentence(tgt)\n",
    "    tgt_seq = tokenizer.texts_to_sequences([tgt])  # 리스트로 감싸줍니다\n",
    "    \n",
    "    tgt_seq = tf.keras.preprocessing.sequence.pad_sequences(tgt_seq,\n",
    "                                                            maxlen=max_len,\n",
    "                                                            padding='post')\n",
    "    \n",
    "    # numpy.ndarray를 다시 리스트로 변환하여 BLEU 계산\n",
    "    src_seq_list = src_seq.tolist()[0]\n",
    "    tgt_seq_list = tgt_seq.tolist()[0]\n",
    "\n",
    "    score = sentence_bleu([src_seq_list], tgt_seq_list,\n",
    "                          smoothing_function=SmoothingFunction().method1)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8116285",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bleu(src_sentences, tgt_sentence):\n",
    "    \n",
    "    for x in tqdm(range(len(src_sentences))):\n",
    "        blue = eval_bleu_single(src_sentences[x], tgt_sentence[x])\n",
    "        print(\"target data: \", src_sentences[x])\n",
    "        print(\"pred: \", tgt_sentence[x])\n",
    "        print(\"blue score: \", blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bd611fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0674f933f3ed4f6192d790efda870b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target data:  잠깐 쉬 어도 돼요 .\n",
      "pred:  그래도 사랑 할 수 있 죠 .\n",
      "blue score:  0.8440120604870561\n",
      "target data:  맛난 거 드세요 .\n",
      "pred:  제 가 드리 고 싶 네요 .\n",
      "blue score:  0.8440120604870561\n",
      "target data:  떨리 겠 죠 .\n",
      "pred:  갑자기 설정 한두 사실 으로 았 타 봐요 ...\n",
      "blue score:  0.7660061645363807\n",
      "target data:  좋 아 하 면 그럴 수 있 어요 .\n",
      "pred:  좋 은 결정 이 아니 에요 .\n",
      "blue score:  0.7981256013410023\n"
     ]
    }
   ],
   "source": [
    "target = [\n",
    "            \"잠깐 쉬 어도 돼요 .\",\n",
    "            \"맛난 거 드세요 .\",\n",
    "            \"떨리 겠 죠 .\",\n",
    "            \"좋 아 하 면 그럴 수 있 어요 .\"\n",
    "]\n",
    "\n",
    "pred = result_list_lsit[13]\n",
    "\n",
    "eval_bleu(target, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68508e93",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863b3e68",
   "metadata": {},
   "source": [
    "예전 부터 관심 있었던 대화형 챗봇을 드디어 해보니 좋은것 같다.\n",
    "\n",
    "하지만 성능 자체는 좋지않아 데이터를 늘리면 조금은 성능이 좋아지겠지 라는 생각을 해본다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
