# 학습 내용

---

- Segment Anything

---

## Segment Anything

---

### Abstract

---

  - image segmentation을 위한 새로운 작업, 모델, 데이터 세트인 Segment Anything 프로젝트 소개함
    - 데이터 수집 루프에서 효율적인 모델을 사용해 1,100만개의 라이센스가 있음
    - 개인 정보를 존중하는 이미지에 10억개 이상의 마스크가 포함된 지금따지 가장 큰 규모의 segment 데이터 세트 구축
    - 모델은 즉시 사용 가능하도록 설계 및 학습되어 zero-shot을 새로운 이미지 배포 및 작업에 적용할 수 있음
    - 1B 마스크, 1,100만 개의 이미지로 구성된 SAM(Segment Anything Model)과 상관 데이터 세트(SA-1B)를 [https://segment-anything.com](https://segment-anything.com) 에서 공개하고 있음

---

### 1. Introduction

---

  - 이 프로젝트의 성공은 작업, 모델, 데이터 이 세가지 구성 요성에 달려 있음
  - 이를 개발하기 위해 이미지 세분화에 대한 다음 질문을 해결해야 함
    - zero-shot 일반화를 가능하게 하는 작업은?
    - 해당 모델 아키텍쳐는?
    - 이 작업과 모델을 뒷받침할 수 있는 데이터는?
  - 이러한 질문은 서로 얽혀 있으며 포괄적인 솔루션이 필요함
  - 강력한 사전 교육 목표를 제공하고 다양한 다운스트림 애플리케이션을 지원할 수 있는 만큼 일반적인 promptable segmentation 작업을 정의하는 것으로 시작함
    - 유연한 프롬프트를 지원하고 대화형 사용을 허용하기 위해 프롬프트가 표시되면 실시간으로 segmentation mask를 출력할 수 있는 모델이 필요함
    - 모델을 훈련하려면 다양하고 대규모의 데이터 소스가 필요함
      - segmentation을 위한 웹 규모의 데이터 소스가 없기 때문에
      - 이를 해결하기 위해 '데이터 엔진'을 구축
        - 효율적인 모델을 사용해 데이터 수집 지원
        - 새로 수집한 데이터를 사용해 모델을 개선하는 과정을 반복

---

#### Task

---

  - '프롬프트' 기법을 사용해 zero-shot 및 few-shot 자주 수행할 수 있는 작업 방식에서 영감을 얻음
  - 어떤 segmentation 프롬프트가 주어지면 유효한 segmentation mask를 반환하는 것이 목표인 promptable segmentation 작업을 제안
    - 프롬프트
      - 단순히 이미지에서 분할할 대상을 지정하는 것
      - 물체를 식별하는 공간, 텍스트 정보가 포함될 수 있음
    - 유효한 출력 mask의 요건
      - 프롬프트가 모호하고 여러 개체를 나타낼 수 있는 경우에도, 출력은 적어도 그 중하나에 대한 합리적인 mask여야 한다는 것을 의미함
  - 사전 훈련 목표이자 프롬프트 엔지니어링을 통해 일반적인 다운스트림 segmentation 작업을 해결하는 데 사용됨

---

#### Model

---

  - 프롬프트 가능한 segmentation 작업과 실제 사용이라는 목표
    - 모델 아키텍처에 제약 조건을 부과함
      1. 유연한 프롬프트를 지원해야 함
      2. 능동적인 사용을 위해 실시간으로 mask를 계산해야 함
      3. 모호성을 인식할 수 있어야 함
  1. 강력한 이미지 인코더가 이미지 임베딩 계산
  2. 프롬프트 인코더가 프롬프트를 임베딩 계산
  3. 두 정보 소스를 경량 mask 디코더에 결합
  - 세 가지 제약 조건을 모두 충족하는 간단한 설계 발견
  - 이 모델을 Segment Anything Model 또는 SAM이라고 함
    - 이미지 인코더와 빠은 프롬프트 인코더, mask 디코더로 분리하면 동일한 이미지 임베딩을 다른 프롬프트에 재사용할 수 있음
    - 웹 브라우저에서 50밀리초 이내에 프롬프트에서 mask를 예측
    - 모호성을 인식하도록 하기 위해 하나의 프롬프트에 대해 여러 개의 마스크를 예측하도록 설계 

---

#### Data engine

---

  - 새로운 데이터 분포에 대한 강력한 일반화를 달성하기 위해서는 크고 다양한 mask 세트에 대해 SAM을 훈련 시켜야 한다는 것을 알게 됨
    - mask는 자연적으로 풍부하지 않기 때문에 새로운 전략이 필요했음
  - 우리의 해결책은 "데이터 엔진"을 구축하는 것
    - 즉, 모델 인더 루프 데이터 세트 표기법을 사용해 모델을 공동 개발하는 것
  - 데이터 엔진은 보조 수동, 반자동, 완전 자동의 세 단계로 구성됨
    - 첫 번째 단계
      - SAM이 기존의 대화형 segmentation 설정과 유사하게 어노테이터가 mask에 주석을 달 수 있도록 지원
    - 두 번째 단계
      - SAM이 객체 하위 집합에 대한 마스크를 자동으로 생성해 가능성이 높은 객체 양이온을 표시
      - 주석자는 나머지 객체에 주석을 다는 데 집중
      - mask의 다양성을 높일 수 있음
    - 세 번째 단계
      - SAM에 전경 점의 규칙적인 그리드를 제시해 이미지당 평균 100개의 고품질 mask 생성

---

### 2. Segment Anything Task

---



---

### 3. Segment Anything Model

---



---

### 4. Segment Anything Data Engine

---

  - segmentation mask는 인터넷에 풍부하지 않기 때문에 11억 개의 mask 데이터 세트인 SA-1B를 수집할 수 있도록 데이터 엔진을 구축
  - 데이터 엔진은 세 단계로 구성
    - 모델 지원 수동 주석 단계
    - 자동으로 예측된 마스크와 모델 지원 주석이 혼합된 반자동 단계
    - 주석 입력 없이 모델이 mask를 생성하는 완전 자동 단계
  1. 보조 수동 단계
     - 클래식 대화형 segmentation과 유사
     - 전문 어노테이터 팀이 SAM으로 구동되는 브라우저 기반 대화형 segmentation 도구를 사용해 전경/배경 오브젝트 포인트를 클릭하여 mask에 라벨을 붙임
     - 픽셀 단위의 정밀한 '브러쉬'및 '지우개'도구를 사용해 mask를 다듬을 수 있었음
     - 모델 지원 표기법
       - 미리 계산된 이미지 임베딩을 사용해 브라우저 내에서 직접 실시간으로 실행되므로 진정한 인터랙티브 경험을 구현할 수 있음
     - 객체에 라벨을 붙이는 데 의미론적 제약을 두지 않았음
     - 주석가에게 이름을 붙이거나 설명할 수 있는 사물에 라벨을 붙이도록 제안
       - 이러한 이름이나 설명을 수집하지는 않았음
     - 주석가들은 눈에 잘 띄는 순서대로 사물에 라벨을 붙이도록 요청 받음
       - mask에 주석을 다는 데 30초 이상 걸리면 다음 이미지로 넘어가도록 권장
     - 이 단계를 시작할 때, SAM은 일반적인 공개 segmentation 데이터 세트를 사용해 훈련
     - 충분한 데이터 표기법이 완성된 후에는 새로 주석이 달린 mask만을 사용해 SAM을 재훈련
     - 더 많은 mask가 수집됨에 따라 이미지 인코더의 크기를 ViT-B -> ViT-H로 확장
       - 다른 아키텍처를 발전시켰음
       - 총 6번 모델 재학습
     - 모델이 개선됨에 따라 mask당 평균 주석 처리 시간은 34초에서 14초로 감소
       - 14초는 COCO의 mask 주석보다 6.5배 빠름
       - 극한점을 사용한 바운딩 박스 라벨링보다 2배 느린 속도에 불과하다는 점에 주목할 필요가 있음
     - SAM이 개선됨에 따라 이미지당 평균 mask 수는 20개에서 44개로 증가
     - 전체적으로 12만 개의 이미지레서 430만 개의 mask 수집
  2. 반자동 단계
     - 모델의 분류 능력을 향상시키기 위해  mask의 다양성을 높이는 것을 목표
     - 덜 눈에 띄는 객체에 어노테이터의 주의를 집중시키기 위해 먼저 확실한 mask를 자동으로 감지
       - 그런 다음 주석가에게 이러한 mask로 미리 채워진 이미지를 제시하고 주석을 달리지 않은 추가 객체에 주석을 달도록 요청
     - 신뢰도 높은 mask를 감지하기 위해 일반적인 "객체"범주를 사용해 모든 1단계 mask에 대해 경계 상자 검출기를 훈련시켰음
     - 이 단계에서 18만 개의 이미지에서 590만개의 mask를 추가로 수집
       - 새로 수집한 데이터에 대해 주기적으로 모델 재학습
     - mask당 평균 어노테이션 시간은 최대 34초까지 소요됨
       - 이러한 물체가 라벨링하기 더 까다롭기 때문
     - 이미지당 평균 mask 수는 44개 -> 72(자동 mask 포함)로 증가
  3. 완전 자동 단계
     - 주석이 완전 자동으로 처리되었음
     - 모델에 두 가지 주여 개선 사항이 있었기 때문에 가능
       1. 이전 단계의 다양한 mask를 포함해 모델을 크게 개선할 수 있는 충분한 mask 수집
       2. 모호성 인식 모델을 개발해 모호한 경우에도 유효한 mask를 예측할 수 있게 됨
          - 모호성 인식 모델을 사용하면 점이 부분 또는 하위 부분에 있는 경우
            - 모델이 하위 부분, 부분 및 전체 객체를 반환
          - 모델의 IoU 예측 모듈
            - 신뢰도 높은 mask를 선별해 사용되며, 안정적인 마스크만 식별하고 선택함
              - 확률 맵을 0.5 ~ δ 및0.5 + δ로 임계값을 설정
              - 유사한 마스크가 나오는 경우 안정적인 마스크로 간주
            - 확실하고 안정적인 mask를 선택한 후 비최대 억제(NMS)를 적용해 중복을 필터링
          - 작은 mask의 품질을 다욱 향상시키기 위해 여러 개의 겹쳐진 이미지 크롭도 처리
     - 데이터 세트의 모든 1,100만 개 이미지에 완전 자동 마스크 생성을 적용
       - 총 11억 개의 고품딜 mask를 생성 
