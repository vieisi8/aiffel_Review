# 학습 내용

---

- Masked Autoencoders Are Scalable Vision Learners

---

## Masked Autoencoders Are Scalable Vision Learners

---

---

### Abstract

---

  - masked autoencoder(MAE)가 컴퓨터 비전을 위한 확장 가능한  self-supervised learner(자기 지도 학습자) 임을 보여줌
  - 입력 이미지의 무작위 패치를 마스킹하고 누락된 픽셀을 재구성하는 MAE 접근 방식은 간단함
  - 두가지 핵심 설계를 기반으로 함
    - 비대칭 인코더-디코더 아키텍쳐를 개발해
      - 마스크 토큰 없이 보이는 패치 하위 집합에서만 작동하는 인코더
      - 잠재 표현 및 마스크 토큰으로부터 원본 이미지를 재구성하는 경량 디코더
    -  입력 이미지의 높은 비율(ex) 75%)을 마스킹하면 사소하지 않고 의미 있는 자체 감독 작업을 수행할 수 있다는 사실 발견
  - 위 두가지 기법을 결합하면
    - 대규모 모델을 효율적이고 효과적으로 훈련할 수 있음
    - 훈련 속도(3배 이상)와 정확도를 높일 수 있음
  - 확장 가능한 접근 방식을 통해 일반화가 잘 되는 고용량 모델을 학습할 수 있음
  - 다운 스트림 작업에서의 전송 성능은 감독된 사전 훈련보다 뛰어나며 유망한 확장 동작을 보여줌

---

### 1. Introduction

---

![image](https://github.com/user-attachments/assets/279a38aa-3250-47e4-9541-375be4a96ca6)

  - 인코더
    - 보이는 패치의 작은 하위 집합에 적용
    - 마스크 토큰은 인코더 다음에 도입
  - 디코더
    - 인코딩된 패치와 마스크 토큰의 전체 세트는 원본 이미지를 픽셀 단위로 재구성하는 소형 디코더에 의해 처리 됨
  - 사전 학습 후 인코더만 사용하며, 인식 작업을 위해 손상되지 않은 이미지(전체 패치 세트)에 적용

---

### 3. Approach

---

  - masked autoencoder(MAE)는 부분적으로 관측된 신호를 바탕으로 원본 신호를 재구성하는 간단한 자동 인코딩 방식
  - 관찰된 신호를 잠재 표현에 매핑하는 인코더와 잠재 표현에서 원본 신호를 재구성하는 디코더가 있음
    - 기존 autoencoder와 달리, 비대칭 설계를 체택해 인코더가 마스크 토큰 없이 관찰된 부분 신호에서만 작동하도록 함
    - 경량 디코더는 잠재 표현과 마스크 토큰으로부터 전체 신호를 재구성

---

#### Masking

---

  - ViT에 따라 이미지를 규칙적으로 겹치지 않은 패치로 나눔
  - 패치의 하위 집합을 샘플링하고 나머지 패치를 마스킹함
  - 샘플링 전략
    - 균일한 분포에 따라 교페 없이 무작위로 패치 샘플링
    - 무작위 샘플링이라 함
  - 마스킹 비율이 높은 무작위 샘플링
    - 중복성을 크게 제거해 보이는 인접 패치에서 외샵으로 쉽게 해결할 수 없는 작업 생성
  - 균일한 분포
    - 잠재적인 중심 편향(이미지 중심 근처에 더 많은 마스킹된 패치)을 방지
  - 매우 희박한 입력
    - 효울적인 인코더를 설계할 수 있는 기회 제공

---

#### MAE encoder

---

  - 당사의 인코더는 ViT이지만 마스킹되지 않은 가시적인 패치에만 적용됨
  - 위치 임베딩이 추가된 선형 투영을 통해 패치를 임베딩한 다음 일련의 Transformer 블록을 통해 결과 집합 처리
    - 전체 세트의 작은 하위 집합에서만 작동
    - 따라서 적은 컴퓨팅 자원으로도 매우 큰 인코더를 훈련할 수 있음
  - 전체 세트
    - 경량 디코더가 처리함

---

#### MAE decoder

---

  - 디코더에 대한 입력
    1. 인코딩된 보이는 패치로 구성도니 전체 토큰 세트
    2. 마스크 토큰
  - 각 마스크 토큰은
    - 공유되고 학습된 벡터로, 미스-패치를 예측할 수 있음
  - 이 전체 세트의 모든 토큰에 위치 임베딩을 추가함
    - 이 기능이 없으면 마스크 토큰은 이미지에서 자신의 위치에 대한 정보를 갖지 못함
  - 디코더는 이미지 재구성 작업을 수행하기 위한 사전 학습 중에만 사용됨
    - 인코더만 인식을 위한 이미지 표현을 생성하는 데 사용됨
  - 디코더 아키텍처
    - 인코더 설계와 독립적인 방식으로 유연하게 설계할 수 있음
    - 인코더보다 더 좁고 낮은 매우 작은 디코더로 실험
  - 이러한 비대칭 설계를 통해 전체 토큰 세트는
    - 경량 디코더로만 처리되므로 사전 학습 시간이 크게 단축

---

#### Reconstruction target

---

  - MAE
    - 각 마스킹된 패치의 픽셀값을 예측해 입력을 재구성함
  - 디코더 출력의 각 요소
    - 패치가 나타내는 픽셓 값의 벡터
  - 디코더의 마지막 레이어
    - 출력 채널 수가 패치의 픽셀 값 수와 같은 선형 투영임
  - 디코더의 출력
    - 재구성된 이미지를 형성하도록 재구성됨
  - 손실 함수
    - 픽셀 공간에서 재구성된 이미지와 원본 이미지간의 평균제곱 오차(MSE)를 계산
    - BERT와 유사하게 마스킹된 패치에서만 손실 계산
  - 각 마스킹된 패치의 정규화된 픽셀 값을 재구성 대상으로 하는 변형도 연구함
    - 패치에 있는 모든 픽셀의 평균과 표준 편차를 계산해 이 패치를 정규화하는 데 사용함
  - 정규화된 픽셀을 재구성 대상으로 사용하면
    - 실험에서 표현 품질이 향상됨

---

#### Simple implementation

---

  - MAE 사전 학습은 효율적으로 구현할 수 있으며, 중요한 것은 특별한 회소 연산을 필요로 하지 않는다는 점
    1. 먼저 모든 입력 패치에 대해 토큰 생성(조건부 임베딩을 추가한 선형 투영 방식)
    2. 마스킹 비율에 따라 토큰 목록을 무작위로 섞고 목록의 마지막 부분을 제거함
       - 위 프로세스는 인코더를 위항 토큰의 작은 하위 집합을 생성, 교페 없이 패치를 샘플링하는 것과 동일함
    3. 인코딩 후에는 인코딩된 패치 목록에 마스크 토큰 목록을 추가, 이 전체 목록을 셔플 해제(무작위 셔플 작업 반전)해 모든 토큰을 타켓에 맞춤
    4. 디코더는 이 전체 목록에 적용됨(위치 임베딩이 추가됨)
       - 회소 연산이 필요하지 않음
  - 셔플링과 언셔플링 연산이 빠르기 때문에 오버헤드가 거의 발생하지 않음
